# Project: favorites-extension

## Overview
This project is primarily written in Python (33%), Markdown (11%), JSON (5%), HTML (4%), JavaScript (4%) and uses the following technology stack: Docker, Git, HTML, JSON, JavaScript, Markdown, Python.

## Dependencies
The main dependencies for this project are: No recognized dependency file found

## Project Structure
The following is a concise directory tree of the project, limited to 3 levels deep and excluding common non-source directories:

├── server
│   ├── main.py
│   ├── api_test.py
│   ├── database.py
│   ├── DESIGN.md
│   ├── favorites_router.py
│   ├── folder_structure.json
│   ├── folders_router.py
│   ├── initDB.py
│   ├── llm.py
│   ├── models.py
│   ├── schemas.py
│   ├── services.py
│   ├── tags_router.py
│   ├── task_queue.py
│   ├── testCreate.py
│   ├── templates
│   │   ├── generate_fallback_description.j2
│   │   ├── suggest_folder.j2
│   │   ├── suggest_tags.j2
│   │   └── summarize_content.j2
│   ├── requirements.txt
│   ├── content_extractor.py
│   ├── cleanTasksDB.py
│   └── update_data_paths.py
├── README.md
├── extension
│   ├── manifest.json
│   ├── popup.html
│   └── popup.js
└── Dockerfile


## Selected Files
The contents of specifically selected files are included below. Each file is preceded by its relative path within the project structure.

## Instructions for Analysis
When analyzing this project:
1. Consider the overall project structure and how the selected files fit within it.
2. Pay attention to the relationships between different files and directories.
3. Be prepared to answer questions about specific files, overall project architecture, or potential improvements.
4. If asked to modify or extend the project, ensure suggestions are consistent with the existing structure and style.

File: server\main.py

import logging
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import uuid
from contextlib import asynccontextmanager
from sqlalchemy import create_engine, inspect, text
from sqlalchemy.orm import Session, sessionmaker
from database import Base, engine, SessionLocal
import models
from favorites_router import router as favorites_router
from folders_router import router as folders_router
from tags_router import router as tags_router
from vector_store import vector_store
import os
import json
import schemas
from services import favorite_service
from task_queue import task_queue

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def clear_tables():
    inspector = inspect(engine)
    all_tables = inspector.get_table_names()
    tables_to_keep = []  # We're not keeping any tables now, as favorites_embeddings is not in SQLite

    with SessionLocal() as session:
        for table in all_tables:
            if table not in tables_to_keep:
                session.execute(text(f"DELETE FROM {table}"))
                logger.info(f"Cleared table: {table}")
        session.commit()

    logger.info("Cleared all non-embedding tables.")
    Base.metadata.create_all(engine)
    logger.info("Ensured all tables exist.")

def create_folder(session, name, parent=None, description=None):
    folder = models.Folder(name=name, description=description)
    if parent:
        folder.parent = parent
    session.add(folder)
    session.flush()
    return folder

def create_folder_structure(session, structure, parent=None):
    folder = create_folder(session, structure['name'], parent, structure.get('description'))
    for child in structure.get('children', []):
        create_folder_structure(session, child, folder)

def check_running_tasks():
    tasks = task_queue.get_all_tasks()
    running_tasks = [task for task in tasks if task["status"] == "processing"]
    return len(running_tasks) > 0

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Clear the tasks table and handle unprocessed favorites
    db = SessionLocal()
    try:
        # Clear all tasks
        db.query(models.Task).delete()
        db.commit() 
    except Exception as e:
        logger.error(f"Error during startup: {str(e)}")
        db.rollback()
    finally:
        db.close()
    
    yield  # This is where the app runs
    
    # Shutdown: Add any cleanup code here if needed
    pass

def create_application() -> FastAPI:
    application = FastAPI(
        lifespan=lifespan,
        title="Intelligent Favorites Extension API",
        description="""
        This API provides endpoints for managing an intelligent favorites system. 
        It allows users to create, retrieve, update, and delete favorites, folders, and tags. 
        The system also provides intelligent features such as automatic summarization, 
        tag suggestion, and folder recommendation.
        """,
        version="1.0.0",
    )

    # Set up CORS
    application.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # Allows all origins
        allow_credentials=True,
        allow_methods=["*"],  # Allows all methods
        allow_headers=["*"],  # Allows all headers
    )

    # Initialize database
    Base.metadata.create_all(bind=engine)

    # Include routers
    application.include_router(favorites_router, prefix="/api/favorites", tags=["favorites"])
    application.include_router(folders_router, prefix="/api/folders", tags=["folders"])
    application.include_router(tags_router, prefix="/api/tags", tags=["tags"])

    return application

app = create_application()

@app.get("/", tags=["root"])
async def root():
    logger.info("Root endpoint accessed")
    return {"message": "Welcome to the Intelligent Favorites Extension API"}

@app.post("/api/reset/", tags=["root"])
async def reset_database():
    if check_running_tasks():
        raise HTTPException(status_code=409, detail="Cannot reset database while tasks are running")
    
    try:
        clear_tables()
        
        # Recreate initial folder structure
        with SessionLocal() as session:
            with open('folder_structure.json', 'r') as f:
                folder_structure = json.load(f)
            create_folder_structure(session, folder_structure)
            session.commit()
        
        return {"message": "Database reset successful"}
    except Exception as e:
        logger.error(f"Error resetting database: {str(e)}")
        raise HTTPException(status_code=500, detail="Error resetting database")

@app.post("/api/reindex/", tags=["root"])
async def reindex_database(db: Session = Depends(SessionLocal)):
    if check_running_tasks():
        raise HTTPException(status_code=409, detail="Cannot reindex database while tasks are running")
    
    try:
        # Get all existing favorites
        existing_favorites = db.query(models.Favorite).all()
        
        # Clear and recreate tables
        clear_tables()
        
        # Recreate initial folder structure
        with open('folder_structure.json', 'r') as f:
            folder_structure = json.load(f)
        create_folder_structure(db, folder_structure)
        db.commit()
        
        # Prepare favorites for reindexing
        favorites_to_import = []
        for favorite in existing_favorites:
            metadata = {
                "summary": favorite.summary,
                "tags": [tag.name for tag in favorite.tags]
            }
            favorite_data = schemas.FavoriteImport(
                url=favorite.url,
                title=favorite.title,
                metadata=json.dumps(metadata)
            )
            favorites_to_import.append(favorite_data)
        
        # Use import_favorites function to reindex
        task_name = f"Reindex Favorites: {len(favorites_to_import)} items"
        result = favorite_service.import_favorites(favorites_to_import, task_name)
        
        return {"message": f"Database reindexing started with {len(favorites_to_import)} favorites", "task_id": result["task_id"]}
    except Exception as e:
        logger.error(f"Error reindexing database: {str(e)}")
        raise HTTPException(status_code=500, detail="Error reindexing database")

if __name__ == "__main__":
    import uvicorn
    logger.info("Starting the Intelligent Favorites Extension API")
    chroma_db_path = os.path.abspath("chroma_db")
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        # reload=False,
        # reload_includes="*.py",
        # reload_excludes=[chroma_db_path],
        log_level="info"
    )

---

File: README.md

# Intelligent Favorites Extension

## Overview

The Intelligent Favorites Extension is a sophisticated browser extension designed to enhance the bookmarking experience. It leverages advanced natural language processing techniques to automatically categorize, summarize, and tag web pages, making it easier for users to organize and retrieve their favorite content.

## Features

- **Automatic Summarization**: Generates concise summaries of bookmarked web pages using advanced NLP models.
- **Intelligent Tagging**: Suggests relevant tags based on the content of the bookmarked page.
- **Smart Folder Organization**: Recommends appropriate folders for new bookmarks based on their content.
- **Semantic Search**: Enables users to find bookmarks using natural language queries.
- **Browser Integration**: Seamlessly integrates with Microsoft Edge as a browser extension.
- **Web Interface**: Provides a user-friendly web interface for managing bookmarks, folders, and tags.
- **API Backend**: Powered by a robust FastAPI backend for efficient data management and processing.

## System Architecture

The system consists of two main components:

1. **Backend API** (Python-based)
   - Framework: FastAPI
   - Database: SQLite (structured data) and Chroma.db (vector embeddings)
   - NLP Models: 
     - LLM: phi3.5 (via Ollama) for chat completion and summarization
     - Embeddings: nomic-embed-text (via Ollama) for semantic search and clustering
   - Deployment: Windows Service

2. **Frontend Extension** (Microsoft Edge Extension)
   - Technologies: HTML, CSS, JavaScript
   - API Communication: Fetch API

## Installation

### Backend Setup

1. Clone the repository:
   ```
   git clone https://github.com/your-repo/intelligent-favorites.git
   cd intelligent-favorites
   ```

2. Install required Python packages:
   ```
   pip install -r requirements.txt
   ```

3. Initialize the database:
   ```
   python initDB.py
   ```

4. Start the FastAPI server:
   ```
   uvicorn main:app --reload
   ```

### Extension Setup

1. Open Microsoft Edge and navigate to `edge://extensions/`
2. Enable "Developer mode"
3. Click "Load unpacked"
4. Select the `extension` folder from the cloned repository

## Usage

1. **Adding a Favorite**: 
   - Click the extension icon in your browser
   - Review the automatically generated title and click "Add Favorite"

2. **Viewing Favorites**:
   - Open the main page by clicking "Open Main Page" in the extension popup
   - Browse your favorites, organized by folders and tags

3. **Searching Favorites**:
   - Use the search bar on the main page to find favorites using natural language queries

4. **Managing Folders and Tags**:
   - Use the web interface to create, edit, or delete folders and tags

5. **Accessing Admin Features**:
   - Click "Open Admin Page" in the extension popup to access advanced management features

## Development

- Backend code is located in the `server` directory
- Frontend extension code is in the `extension` directory
- Run tests using `pytest`:
  ```
  pytest api_test.py
  ```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgements

- Icons provided by [Icons8](https://icons8.com)
- NLP models and services:
  - [Ollama](https://ollama.ai/) - Local LLM inference
  - [OpenAI](https://openai.com/) - Cloud-based LLM services
  - [Anthropic](https://www.anthropic.com/) - Advanced AI models including Claude
- Frontend libraries:
  - [React](https://reactjs.org/)
  - [Tailwind CSS](https://tailwindcss.com/)

---

File: extension\manifest.json

{
  "manifest_version": 3,
  "name": "Intelligent Favorites",
  "version": "1.0",
  "description": "Add favorites to your Intelligent Favorites system",
  "permissions": [
    "activeTab",
    "scripting"
  ],
  "action": {
    "default_popup": "popup.html",
    "default_icon": {
      "24": "icons8-favorite-dark-24.png",
      "48": "icons8-favorite-dark-48.png",
      "96": "icons8-favorite-dark-96.png"
    }
  },
  "icons": {
    "24": "icons8-favorite-dark-24.png",
    "48": "icons8-favorite-dark-48.png",
    "96": "icons8-favorite-dark-96.png"
  },
  "web_accessible_resources": [
    {
      "resources": ["search.html"],
      "matches": ["<all_urls>"]
    }
  ]
}

---

File: extension\popup.html

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Intelligent Favorites</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            width: 300px;
            padding: 16px;
            background-color: #f0f0f0;
            color: #333;
        }
        h1 {
            font-size: 18px;
            margin-bottom: 16px;
        }
        input, button {
            width: 100%;
            padding: 8px;
            margin-bottom: 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            box-sizing: border-box;
        }
        button {
            background-color: #0078d4;
            color: white;
            border: none;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #106ebe;
        }
        #message {
            margin-top: 12px;
            font-weight: bold;
        }
        .link {
            display: block;
            margin-top: 12px;
            color: #0078d4;
            text-decoration: none;
        }
        .link:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Add Favorite</h1>
    <input type="text" id="titleInput" placeholder="Title">
    <button id="addButton">Add Favorite</button>
    <button id="searchButton">Search Favorites</button>
    <div id="message"></div>
    <script src="popup.js"></script>
</body>
</html>

---

File: extension\popup.js

document.addEventListener('DOMContentLoaded', function() {
    chrome.tabs.query({active: true, currentWindow: true}, function(tabs) {
        let currentTab = tabs[0];
        document.getElementById('titleInput').value = currentTab.title;
    });
    document.getElementById("searchButton").addEventListener("click", openSearchDialog);
});

function formatMetaInfoForLLM(metaInfo) {
    const relevantFields = [
        "title",
        "description",
        "keywords",
        "og:title",
        "og:description",
        "og:type",
        "og:url",
        "author",
        "publish_date",
        "article:published_time",
        "article:author",
    ];

    let formattedString = "Webpage Metadata:\n";

    for (const field of relevantFields) {
        if (metaInfo[field]) {
            formattedString += `${field}: ${metaInfo[field]}\n`;
        }
    }

    return formattedString.trim();
}

document.getElementById("addButton").addEventListener("click", async () => {
    // This function will be executed in the context of the current tab
    function getMetaDescription() {
        const metaInfo = {};

        // Extract title
        metaInfo.title = document.title;

        // Extract meta tags
        const metaTags = document.getElementsByTagName("meta");
        for (let i = 0; i < metaTags.length; i++) {
            const name = metaTags[i].getAttribute("name");
            const property = metaTags[i].getAttribute("property");
            const content = metaTags[i].getAttribute("content");

            if (name) {
                metaInfo[name.toLowerCase()] = content;
            } else if (property) {
                metaInfo[property.toLowerCase()] = content;
            }
        }

        // Extract Open Graph tags
        const ogTitle = document.querySelector('meta[property="og:title"]');
        const ogDescription = document.querySelector('meta[property="og:description"]');
        const ogImage = document.querySelector('meta[property="og:image"]');

        if (ogTitle) metaInfo["og:title"] = ogTitle.getAttribute("content");
        if (ogDescription) metaInfo["og:description"] = ogDescription.getAttribute("content");
        if (ogImage) metaInfo["og:image"] = ogImage.getAttribute("content");

        return metaInfo;
    }

    // Get the current active tab
    let [tab] = await chrome.tabs.query({ active: true, currentWindow: true });

    // Execute script in the context of the active tab
    chrome.scripting.executeScript(
        {
            target: { tabId: tab.id },
            function: getMetaDescription,
        },
        (results) => {
            // Log the result to the extension's console
            console.log(results[0].result);

            // Format the metaInfo for LLM prompt
            const formattedMetaInfo = formatMetaInfoForLLM(results[0].result);
            console.log("Formatted Meta Info for LLM:");
            console.log(formattedMetaInfo);

            const favoriteData = {
                url: tab.url,
                title: document.getElementById('titleInput').value,
                metadata: formattedMetaInfo,
            };

            const messageDiv = document.getElementById("message");

            fetch("http://localhost:8000/api/favorites/", {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                },
                body: JSON.stringify(favoriteData),
            })
                .then((response) => response.json())
                .then((data) => {
                    messageDiv.textContent = "Favorite added successfully!";
                    messageDiv.style.color = "green";
                })
                .catch((error) => {
                    messageDiv.textContent = "Error adding favorite.";
                    messageDiv.style.color = "red";
                    console.error("Error:", error);
                });
        }
    );
});

function openSearchDialog() {
    chrome.windows.create({
        url: chrome.runtime.getURL("search.html"),
        type: "popup",
        width: 400,
        height: 600
    }, function(window) {
        // Close the main extension popup
        window.chrome.windows.getCurrent(function(currentWindow) {
            chrome.windows.remove(currentWindow.id);
        });
    });
}

---

File: server\api_test.py

import pytest
import logging
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy.exc import IntegrityError

from main import app
from database import Base
from services import favorite_service, folder_service, tag_service

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Use an in-memory SQLite database for testing
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"

engine = create_engine(
    SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False}
)
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create a new database session for each test
@pytest.fixture(scope="function")
def db():
    logger.info("Setting up test database")
    Base.metadata.create_all(bind=engine)
    db = TestingSessionLocal()
    try:
        yield db
    finally:
        db.close()
        Base.metadata.drop_all(bind=engine)
        logger.info("Tearing down test database")

# Create a test client
@pytest.fixture(scope="module")
def client():
    logger.info("Creating test client")
    with TestClient(app) as c:
        yield c

# Test favorite endpoints
def test_create_favorite(client, db):
    logger.info("Testing create favorite endpoint")
    response = client.post(
        "/api/favorites/",
        json={"url": "https://example.com", "title": "Example", "summary": "An example website"}
    )
    assert response.status_code == 200
    data = response.json()
    assert data["url"] == "https://example.com/"  # Note the trailing slash
    assert data["title"] == "Example"
    assert "id" in data
    logger.info(f"Created favorite with id: {data['id']}")

def test_read_favorite(client, db):
    logger.info("Testing read favorite endpoint")
    # First, create a favorite
    create_response = client.post(
        "/api/favorites/",
        json={"url": "https://example.com", "title": "Example", "summary": "An example website"}
    )
    favorite_id = create_response.json()["id"]
    logger.info(f"Created favorite with id: {favorite_id}")

    # Then, read the favorite
    response = client.get(f"/api/favorites/{favorite_id}")
    assert response.status_code == 200
    data = response.json()
    assert data["url"] == "https://example.com/"  # Note the trailing slash
    assert data["title"] == "Example"
    logger.info("Read favorite test passed")

def test_update_favorite(client, db):
    logger.info("Testing update favorite endpoint")
    # First, create a favorite
    create_response = client.post(
        "/api/favorites/",
        json={"url": "https://example.com", "title": "Example", "summary": "An example website"}
    )
    favorite_id = create_response.json()["id"]
    logger.info(f"Created favorite with id: {favorite_id}")

    # Then, update the favorite
    response = client.put(
        f"/api/favorites/{favorite_id}",
        json={"title": "Updated Example", "summary": "An updated example website"}
    )
    assert response.status_code == 200
    data = response.json()
    assert data["title"] == "Updated Example"
    assert data["summary"] == "An updated example website"
    logger.info("Update favorite test passed")

def test_delete_favorite(client, db):
    logger.info("Testing delete favorite endpoint")
    # First, create a favorite
    create_response = client.post(
        "/api/favorites/",
        json={"url": "https://example.com", "title": "Example", "summary": "An example website"}
    )
    favorite_id = create_response.json()["id"]
    logger.info(f"Created favorite with id: {favorite_id}")

    # Then, delete the favorite
    response = client.delete(f"/api/favorites/{favorite_id}")
    assert response.status_code == 200
    logger.info(f"Deleted favorite with id: {favorite_id}")

    # Verify that the favorite has been deleted
    get_response = client.get(f"/api/favorites/{favorite_id}")
    assert get_response.status_code == 404
    logger.info("Delete favorite test passed")

# Test folder endpoints
def test_create_folder(client, db):
    logger.info("Testing create folder endpoint")
    response = client.post(
        "/api/folders/",
        json={"name": "Test Folder", "description": "A test folder"}
    )
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "Test Folder"
    assert "id" in data
    logger.info(f"Created folder with id: {data['id']}")

def test_read_folder(client, db):
    logger.info("Testing read folder endpoint")
    # First, create a folder
    create_response = client.post(
        "/api/folders/",
        json={"name": "Test Folder", "description": "A test folder"}
    )
    folder_id = create_response.json()["id"]
    logger.info(f"Created folder with id: {folder_id}")

    # Then, read the folder
    response = client.get(f"/api/folders/{folder_id}")
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "Test Folder"
    assert data["description"] == "A test folder"
    logger.info("Read folder test passed")

# Test tag endpoints
def test_create_tag(client, db):
    logger.info("Testing create tag endpoint")
    response = client.post(
        "/api/tags/",
        json={"name": "TestTag"}
    )
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "TestTag"
    assert "id" in data
    logger.info(f"Created tag with id: {data['id']}")

def test_read_tag(client, db):
    logger.info("Testing read tag endpoint")
    # First, create a tag
    create_response = client.post(
        "/api/tags/",
        json={"name": "UniqueTestTag"}  # Use a unique name
    )
    tag_id = create_response.json()["id"]
    logger.info(f"Created tag with id: {tag_id}")

    # Then, read the tag
    response = client.get(f"/api/tags/{tag_id}")
    assert response.status_code == 200
    data = response.json()
    assert data["name"] == "UniqueTestTag"
    logger.info("Read tag test passed")

# Test search functionality
def test_search_favorites(client, db):
    logger.info("Testing search favorites endpoint")
    # Create some favorites
    client.post("/api/favorites/", json={"url": "https://example1.com", "title": "Example 1", "summary": "First example"})
    client.post("/api/favorites/", json={"url": "https://example2.com", "title": "Example 2", "summary": "Second example"})
    logger.info("Created test favorites for search")

    # Perform a search
    response = client.post("/api/search", json={"query": "First example", "limit": 5})
    assert response.status_code == 200, f"Unexpected status code: {response.status_code}. Response: {response.text}"
    data = response.json()
    assert len(data) > 0
    assert data[0]["title"] == "Example 1"
    logger.info("Search favorites test passed")

# Add more tests as needed for other endpoints and edge cases

if __name__ == "__main__":
    logger.info("Running tests...")
    pytest.main([__file__])
    logger.info("All tests completed.")

---

File: server\database.py

from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os

# Get the SQLite database directory from the environment variable
sqlite_dir = os.environ.get('SQLITE_DIR', '.')
database_url = f"sqlite:///{sqlite_dir}/favorites.db"

SQLALCHEMY_DATABASE_URL = database_url

# Create SQLAlchemy engine
engine = create_engine(
    SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False}
)

# Create SessionLocal class
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create Base class
Base = declarative_base()

# Dependency
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# Function to initialize the database
def init_db():
    Base.metadata.create_all(bind=engine)

---

File: server\DESIGN.md

# Microsoft Edge Intelligent Favorites Extension - Design Document

## 1. Introduction

This document outlines the design for an intelligent favorites management extension for Microsoft Edge. The extension will allow users to store, organize, summarize, and search their favorites using advanced natural language processing techniques.

## 2. System Architecture

The system consists of two main components:
1. Backend API (Python-based)
2. Frontend Extension (Microsoft Edge Extension)

### 2.1 Backend API

- Framework: FastAPI
- Database: SQLite (for structured data) and Chroma.db (for vector embeddings)
- NLP Models: 
  - LLM: phi3.5 (via Ollama) for chat completion and summarization
  - Embeddings: nomic-embed-text (via Ollama) for semantic search and clustering
- Deployment: Windows Service

### 2.2 Frontend Extension

- Technologies: HTML, CSS, JavaScript
- API Communication: Fetch API

## 3. Data Model

### 3.1 SQLite Schema

```sql
-- Folders table
CREATE TABLE folders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    parent_id INTEGER,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (parent_id) REFERENCES folders(id)
);

-- Favorites table
CREATE TABLE favorites (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    url TEXT NOT NULL,
    title TEXT,
    summary TEXT,
    folder_id INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (folder_id) REFERENCES folders(id)
);

-- Tags table
CREATE TABLE tags (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE
);

-- Favorites-Tags association table
CREATE TABLE favorites_tags (
    favorite_id INTEGER,
    tag_id INTEGER,
    PRIMARY KEY (favorite_id, tag_id),
    FOREIGN KEY (favorite_id) REFERENCES favorites(id),
    FOREIGN KEY (tag_id) REFERENCES tags(id)
);
```

### 3.2 Chroma.db Schema

Collection name: `favorites_embeddings`

Schema:
- id: favorite.id
- embedding: nomic-embed-text generated embedding
- metadata:
  - url: favorite.url
  - title: favorite.title
  - summary: favorite.summary
  - folder_id: favorite.folder_id
  - tags: comma-separated list of tag names

## 4. API Endpoints

### 4.1 Favorites Management

- POST /api/favorites
  - Add a new favorite
  - Parameters: url, content (optional), folder_id (optional)
  - Returns: Favorite object with generated summary and suggested tags

- GET /api/favorites/{id}
  - Retrieve a specific favorite
  - Returns: Favorite object with all associated data

- PUT /api/favorites/{id}
  - Update a favorite
  - Parameters: title, summary, folder_id, tags

- DELETE /api/favorites/{id}
  - Remove a favorite

- GET /api/favorites
  - List favorites
  - Parameters: folder_id (optional), tag (optional), search_query (optional)
  - Returns: List of favorite objects

### 4.2 Folder Management

- POST /api/folders
  - Create a new folder
  - Parameters: name, parent_id (optional), description

- GET /api/folders/{id}
  - Retrieve folder details

- PUT /api/folders/{id}
  - Update folder information
  - Parameters: name, parent_id, description

- DELETE /api/folders/{id}
  - Remove a folder
  - Parameters: move_to_parent (boolean, optional)

- GET /api/folders
  - List folder structure
  - Returns: Tree-like structure of folders

### 4.3 Search and Suggestions

- POST /api/search
  - Perform semantic search on favorites
  - Parameters: query, limit (optional)

- GET /api/suggest-tags
  - Get tag suggestions for given content
  - Parameters: content or url

- GET /api/suggest-folder
  - Get folder placement suggestion for given content
  - Parameters: content or url

## 5. Key Features and Workflows

### 5.1 Adding a New Favorite

1. User clicks the extension button or uses a keyboard shortcut
2. Extension frontend sends the current page URL to the backend
3. Backend scrapes the content (if not provided) and processes it:
   a. Generates a summary using phi3.5
   b. Creates an embedding using nomic-embed-text
   c. Suggests tags based on content clustering
   d. Suggests a folder based on content analysis
4. User reviews and optionally modifies the suggestions
5. Favorite is saved to the database with all associated data

### 5.2 Searching Favorites

1. User enters a search query in the extension's search bar
2. Query is sent to the backend
3. Backend performs:
   a. Semantic search using Chroma.db
   b. Optional keyword-based search on titles and summaries
4. Results are returned and displayed in the extension UI

### 5.3 Organizing Favorites

1. User navigates the folder structure in the extension UI
2. When moving a favorite:
   a. User selects the favorite and chooses "Move"
   b. Backend suggests folders based on content similarity
   c. User selects a destination folder
   d. Backend updates the favorite's folder_id

## 6. LLM Integration

### 6.1 Content Summarization

- Use phi3.5 to generate concise summaries (2-3 sentences) of favorited web pages
- Prompt engineering will be crucial for consistent, high-quality summaries

### 6.2 Folder Suggestions

- Analyze the content and existing folder structure
- Use phi3.5 to suggest the most appropriate existing folder or propose a new one
- Generate folder descriptions for new folders

### 6.3 Tag Generation

- Use nomic-embed-text to create embeddings for favorites
- Cluster similar favorites and use phi3.5 to generate descriptive tags for each cluster

## 7. Extension UI Design

### 7.1 Popup Interface

- Quick add favorite button
- Search bar
- Recent favorites list
- Quick access to main categories/folders

### 7.2 Full Page Interface

- Complete folder structure navigation
- Advanced search options
- Favorite management (edit, move, delete)
- Tag management
- Settings and customization options

## 8. Security and Privacy

- Implement user authentication for API access
- Use HTTPS for all API communications
- Store sensitive data (e.g., authentication tokens) securely
- Provide options for users to control data storage and deletion

## 9. Performance Optimization

- Implement caching strategies for frequently accessed data
- Use background scripts for time-consuming tasks (e.g., content scraping, summarization)
- Optimize database queries and indexing

## 10. Future Enhancements

- Multi-device synchronization
- Collaborative sharing of favorites and folders
- Integration with other browsers or platforms
- Advanced analytics on browsing habits and favorite usage

## 11. Testing Strategy

- Unit tests for backend API functions
- Integration tests for database operations and LLM integrations
- End-to-end tests for extension workflows
- User acceptance testing for UI/UX

## 12. Deployment and Maintenance

### 12.1 Windows Service Setup

- Implement the API server as a Windows service for automatic startup and background operation
- Use a service management library like `win32serviceutil` or `pywin32` for service implementation
- Create service installation and configuration scripts
- Implement logging for service status and error reporting
- Ensure proper error handling and automatic restart capabilities

### 12.2 Service Configuration

- Create a configuration file for service parameters (e.g., port, database location, log file location)
- Implement a method to update service configuration without reinstallation

### 12.3 Monitoring and Management

- Develop a simple management UI or CLI tool for:
  - Starting/stopping the service
  - Viewing service status
  - Accessing logs
  - Updating configuration

### 12.4 Continuous Integration and Deployment

- Set up CI/CD pipeline for automated testing and deployment
- Include service installation and update procedures in the deployment process
- Implement version control for the service configuration

### 12.5 Regular Maintenance

- Monitor API performance and error rates
- Regularly update dependencies and LLM models
- Provide user support and feature request channels
- Schedule regular database backups and maintenance tasks

This design document provides a comprehensive overview of the Microsoft Edge Intelligent Favorites Extension project, including its implementation as a Windows service. It serves as a blueprint for development and can be updated as the project evolves.

---

File: server\favorites_router.py

# favorites_router.py
import logging
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from sqlalchemy.exc import IntegrityError
from typing import List, Dict
from pydantic import ValidationError
from rich import print as rprint
from database import get_db
import schemas
from services import favorite_service, folder_service, nlp_service
from task_queue import task_queue
from models import Task, FavoriteToProcess
from vector_store import vector_store

router = APIRouter()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
    
@router.post("/", response_model=Dict[str, str])
async def create_favorite(favorite: schemas.FavoriteCreate):
    try:
        task_name = f"Create Favorite: {favorite.title}"
        result = favorite_service.create_favorite(favorite, task_name)
        return {"task_id": result["task_id"]}
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/task/{task_id}", response_model=schemas.TaskStatusDetail)
async def get_task_status(task_id: str):
    task_status = task_queue.get_task_status(task_id)
    if task_status is None:
        raise HTTPException(status_code=404, detail="Task not found")
    return schemas.TaskStatusDetail(**task_status)

@router.get("/tasks", response_model=List[schemas.TaskStatus])
async def get_tasks(db: Session = Depends(get_db)):
    tasks = task_queue.get_all_tasks()
    
    # Check if there are any running tasks or existing restartable tasks
    running_tasks = [task for task in tasks if task["status"] == "processing"]
    restartable_tasks = [task for task in tasks if task["status"] == "restartable"]
    
    if not running_tasks and not restartable_tasks:
        # Check for unprocessed tasks in favorites_to_process
        unprocessed_count = db.query(FavoriteToProcess).filter(FavoriteToProcess.processed == False).count()
        
        if unprocessed_count > 0:
            # Create a new restartable task
            restartable_task = Task(
                id=task_queue.generate_task_id(),
                name="Restart Import Favorites",
                status="restartable",
                progress="0",
                result=f"{unprocessed_count} favorites need to be processed"
            )
            db.add(restartable_task)
            db.commit()
            
            # Add the new restartable task to the list of tasks
            tasks.append({
                "id": restartable_task.id,
                "name": restartable_task.name,
                "status": restartable_task.status,
                "progress": restartable_task.progress
            })
    
    return [schemas.TaskStatus(**task) for task in tasks]

@router.post("/restart-import", response_model=Dict[str, str])
async def restart_import():
    try:
        task_name = "Restart Import Favorites"
        result = await favorite_service.restart_import_task(task_name)
        return {"task_id": result["task_id"]}
    except Exception as e:
        logger.error(f"Unexpected error during import restart: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/{favorite_id}", response_model=schemas.Favorite)
def read_favorite(favorite_id: int, db: Session = Depends(get_db)):
    db_favorite = favorite_service.get_favorite(db, favorite_id)
    if db_favorite is None:
        raise HTTPException(status_code=404, detail="Favorite not found")
    return db_favorite

@router.get("/", response_model=List[schemas.Favorite])
def read_favorites(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    return favorite_service.get_favorites(db, skip=skip, limit=limit)

@router.put("/{favorite_id}", response_model=schemas.Favorite)
def update_favorite(favorite_id: int, favorite: schemas.FavoriteUpdate, db: Session = Depends(get_db)):
    updated_favorite = favorite_service.update_favorite(db, favorite_id, favorite)
    if updated_favorite is None:
        raise HTTPException(status_code=404, detail="Favorite not found")
    return updated_favorite

@router.delete("/{favorite_id}", response_model=schemas.Favorite)
def delete_favorite(favorite_id: int, db: Session = Depends(get_db)):
    deleted_favorite = favorite_service.delete_favorite(db, favorite_id)
    if deleted_favorite is None:
        raise HTTPException(status_code=404, detail="Favorite not found")
    return deleted_favorite

@router.post("/suggest-tags", response_model=List[str])
async def suggest_tags(favorite: schemas.FavoriteCreate, db: Session = Depends(get_db)):
    return await nlp_service.suggest_tags(str(favorite.url))

@router.post("/suggest-folder", response_model=int)
async def suggest_folder(favorite: schemas.FavoriteCreate, db: Session = Depends(get_db)):
    return await nlp_service.suggest_folder(db, str(favorite.url))

@router.delete("/", response_model=Dict[str, str])
async def delete_all_favorites():
    try:
        task_name = "Delete All Favorites"
        result = favorite_service.delete_all_favorites(task_name)
        return {"task_id": result["task_id"]}
    except Exception as e:
        logger.error(f"Unexpected error: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/import", response_model=Dict[str, str])
async def import_favorites(favorites: List[schemas.FavoriteImport]):
    try:
        task_name = f"Import Favorites: {len(favorites)} items"
        result = favorite_service.import_favorites(favorites, task_name)
        return {"task_id": result["task_id"]}
    except Exception as e:
        logger.error(f"Unexpected error during import: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
    
@router.get("/search/vector", response_model=List[schemas.Favorite])
async def vector_search_favorites(
    query: str = Query(..., description="The search query"),
    limit: int = Query(10, ge=1, le=100, description="The maximum number of results to return"),
    db: Session = Depends(get_db)
):
    try:
        search_results = vector_store.search_favorites(query, limit)
        favorite_ids = [result["id"] for result in search_results]
        favorites = favorite_service.get_favorites_by_ids(db, favorite_ids)
        return favorites
    except Exception as e:
        logger.error(f"Error searching favorites: {str(e)}")
        raise HTTPException(status_code=500, detail="An error occurred while searching favorites")


---

File: server\folder_structure.json

{
  "name": "Favorites",
  "description": "Root folder for all categories",
  "children": [
    {
      "name": "Technology",
      "description": "Technology-related favorites",
      "children": [
        {
          "name": "Programming",
          "description": "Programming-related resources"
        },
        {
          "name": "Web Development",
          "description": "Web development resources"
        },
        {
          "name": "Mobile Development",
          "description": "Mobile app development resources"
        },
        {
          "name": "Data Science & AI",
          "description": "Data science and artificial intelligence resources"
        },
        {
          "name": "DevOps & Cloud Computing",
          "description": "DevOps and cloud computing resources"
        },
        {
          "name": "Cybersecurity",
          "description": "Cybersecurity resources"
        },
        {
          "name": "Blockchain & Cryptocurrency",
          "description": "Resources on blockchain technology and cryptocurrency"
        },
        {
          "name": "Open Source Projects",
          "description": "Open source project resources"
        },
        {
          "name": "Tech News & Blogs",
          "description": "Technology news and blog resources"
        },
        {
          "name": "Emerging Technologies",
          "description": "Resources on VR, AR, IoT, and other emerging tech"
        },
        {
          "name": "Hardware & Gadgets",
          "description": "Information about the latest hardware and gadgets"
        }
      ]
    },
    {
      "name": "Generative AI",
      "description": "Resources related to generative AI technologies",
      "children": [
        {
          "name": "AI Art & Creativity",
          "description": "Resources for AI-generated art, music, and creative projects"
        },
        {
          "name": "Text Generation",
          "description": "Tools and resources for AI-based text generation"
        },
        {
          "name": "AI Models & Frameworks",
          "description": "Information on generative AI models like GPT, BERT, and DALL-E"
        },
        {
          "name": "AI Ethics & Policy",
          "description": "Discussions on ethics, policy, and implications of generative AI"
        },
        {
          "name": "AI Tools & Software",
          "description": "Software and tools for building and using generative AI models"
        },
        {
          "name": "AI Tutorials & Guides",
          "description": "Tutorials and guides for learning about generative AI"
        },
        {
          "name": "AI News & Research",
          "description": "Latest news, research papers, and articles on generative AI"
        },
        {
          "name": "Communities & Forums",
          "description": "Online communities and forums discussing generative AI"
        }
      ]
    },
    {
      "name": "Learning & Resources",
      "description": "Learning materials and resources",
      "children": [
        {
          "name": "Online Courses",
          "description": "Online course platforms and resources"
        },
        {
          "name": "Tutorials & Guides",
          "description": "Tutorials and how-to guides"
        },
        {
          "name": "Books & eBooks",
          "description": "Technical and educational books"
        },
        {
          "name": "Podcasts & Webinars",
          "description": "Educational podcasts and webinars"
        },
        {
          "name": "Documentation & References",
          "description": "Technical documentation and reference materials"
        },
        {
          "name": "Academic Resources",
          "description": "Scholarly articles, research papers, and academic databases"
        },
        {
          "name": "Language Learning",
          "description": "Resources for learning new languages"
        },
        {
          "name": "Certifications & Exams",
          "description": "Certification resources and exam preparation"
        }
      ]
    },
    {
      "name": "Tools & Software",
      "description": "Useful tools and software",
      "children": [
        {
          "name": "Development Tools",
          "description": "Software development tools"
        },
        {
          "name": "Design Tools",
          "description": "Graphic and UI/UX design tools"
        },
        {
          "name": "Productivity Tools",
          "description": "Tools for improving productivity"
        },
        {
          "name": "Collaboration Tools",
          "description": "Team collaboration and communication tools"
        },
        {
          "name": "Automation Tools",
          "description": "Tools for task and workflow automation"
        },
        {
          "name": "Analytics & Monitoring",
          "description": "Tools for data analytics and system monitoring"
        },
        {
          "name": "Web Hosting & Domain Management",
          "description": "Resources for web hosting and domain management"
        },
        {
          "name": "File Management & Sharing",
          "description": "Tools for managing and sharing files"
        }
      ]
    },
    {
      "name": "Career & Networking",
      "description": "Career development and networking resources",
      "children": [
        {
          "name": "Job Boards & Opportunities",
          "description": "Job listing sites and career opportunities"
        },
        {
          "name": "Professional Networking",
          "description": "Professional networking platforms and resources"
        },
        {
          "name": "Conferences & Meetups",
          "description": "Industry conferences and local meetups"
        },
        {
          "name": "Mentorship & Coaching",
          "description": "Mentorship programs and career coaching resources"
        },
        {
          "name": "Skill Development",
          "description": "Resources for developing professional skills"
        },
        {
          "name": "Freelancing & Gig Economy",
          "description": "Resources for freelancing and gig work"
        }
      ]
    },
    {
      "name": "News & Current Events",
      "description": "News sources and current events",
      "children": [
        {
          "name": "World News",
          "description": "International news sources"
        },
        {
          "name": "Local News",
          "description": "Local and regional news sources"
        },
        {
          "name": "Business & Finance News",
          "description": "Business and financial news resources"
        },
        {
          "name": "Science & Technology News",
          "description": "Science and technology news outlets"
        },
        {
          "name": "Opinion & Analysis",
          "description": "Opinion pieces and in-depth analysis"
        },
        {
          "name": "Politics & Government",
          "description": "Political news and government resources"
        },
        {
          "name": "Environmental News",
          "description": "News related to the environment and climate change"
        }
      ]
    },
    {
      "name": "Hobbies & Lifestyle",
      "description": "Personal interests and lifestyle resources",
      "children": [
        {
          "name": "Travel & Adventure",
          "description": "Travel tips, destinations, and adventure resources"
        },
        {
          "name": "Food & Cooking",
          "description": "Recipes, cooking techniques, and food blogs"
        },
        {
          "name": "Health & Fitness",
          "description": "Health tips, workout routines, and wellness resources"
        },
        {
          "name": "Arts & Culture",
          "description": "Art, music, and cultural resources"
        },
        {
          "name": "Personal Finance & Investment",
          "description": "Financial planning and investment resources"
        },
        {
          "name": "DIY & Crafts",
          "description": "Do-it-yourself projects and crafting resources"
        },
        {
          "name": "Gardening & Home Improvement",
          "description": "Gardening tips and home improvement resources"
        },
        {
          "name": "Fashion & Style",
          "description": "Fashion trends, styling tips, and clothing resources"
        },
        {
          "name": "Mindfulness & Meditation",
          "description": "Resources for mindfulness, meditation, and mental health"
        }
      ]
    },
    {
      "name": "Entertainment",
      "description": "Entertainment and media resources",
      "children": [
        {
          "name": "Movies & TV Shows",
          "description": "Movie and TV show recommendations and reviews"
        },
        {
          "name": "Music & Podcasts",
          "description": "Music streaming services and podcast directories"
        },
        {
          "name": "Books & Literature",
          "description": "Book recommendations and literary resources"
        },
        {
          "name": "Gaming",
          "description": "Video game news, reviews, and gaming platforms"
        },
        {
          "name": "Streaming Services",
          "description": "Online streaming platforms for various media"
        },
        {
          "name": "Comics & Graphic Novels",
          "description": "Resources for comics and graphic novels"
        },
        {
          "name": "Humor & Memes",
          "description": "Websites for humor, memes, and funny content"
        }
      ]
    },
    {
      "name": "Social & Community",
      "description": "Social media and community resources",
      "children": [
        {
          "name": "Social Media Platforms",
          "description": "Various social media websites and apps"
        },
        {
          "name": "Forums & Discussion Boards",
          "description": "Online communities and discussion platforms"
        },
        {
          "name": "Blogging Platforms",
          "description": "Websites for creating and hosting blogs"
        },
        {
          "name": "Social Causes & Volunteering",
          "description": "Resources for social causes and volunteer opportunities"
        },
        {
          "name": "Virtual Communities",
          "description": "Virtual communities and online social spaces"
        },
        {
          "name": "Local Community Groups",
          "description": "Resources for local community groups and events"
        }
      ]
    },
    {
      "name": "E-commerce & Shopping",
      "description": "Online shopping and e-commerce resources",
      "children": [
        {
          "name": "Marketplaces",
          "description": "Online marketplaces for various products"
        },
        {
          "name": "Deals & Coupons",
          "description": "Websites offering deals and discount coupons"
        },
        {
          "name": "Product Reviews",
          "description": "Sites with product reviews and buying guides"
        },
        {
          "name": "Niche Shopping",
          "description": "Specialty shopping websites for niche products"
        },
        {
          "name": "Subscription Services",
          "description": "Online subscription services for various products"
        }
      ]
    },
    {
      "name": "Science & Nature",
      "description": "Resources on science, nature, and the environment",
      "children": [
        {
          "name": "Astronomy & Space",
          "description": "Resources on astronomy and space exploration"
        },
        {
          "name": "Biology & Life Sciences",
          "description": "Information about biology and life sciences"
        },
        {
          "name": "Earth Sciences & Environment",
          "description": "Resources on geology, meteorology, and environmental science"
        },
        {
          "name": "Physics & Chemistry",
          "description": "Resources on physics, chemistry, and related sciences"
        },
        {
          "name": "Ecology & Conservation",
          "description": "Resources on ecology, wildlife, and conservation efforts"
        }
      ]
    },
    {
      "name": "History & Humanities",
      "description": "Resources on history, philosophy, and humanities",
      "children": [
        {
          "name": "World History",
          "description": "Resources on global historical events and periods"
        },
        {
          "name": "Philosophy",
          "description": "Philosophical texts, discussions, and resources"
        },
        {
          "name": "Archaeology",
          "description": "Information on archaeological findings and research"
        },
        {
          "name": "Cultural Studies",
          "description": "Resources on cultural studies and anthropology"
        },
        {
          "name": "Religious Studies",
          "description": "Resources on world religions and spiritual practices"
        }
      ]
    },
    {
      "name": "Art & Design",
      "description": "Resources on art, design, and creativity",
      "children": [
        {
          "name": "Visual Arts",
          "description": "Resources for painting, drawing, and visual arts"
        },
        {
          "name": "Graphic Design",
          "description": "Resources for graphic design and digital art"
        },
        {
          "name": "Photography",
          "description": "Photography tips, tutorials, and galleries"
        },
        {
          "name": "Architecture",
          "description": "Resources on architecture and architectural design"
        },
        {
          "name": "Interior Design",
          "description": "Resources for interior design and home decor"
        }
      ]
    },
    {
      "name": "Health & Wellness",
      "description": "Resources on health, wellness, and medical information",
      "children": [
        {
          "name": "General Health",
          "description": "General health tips and medical information"
        },
        {
          "name": "Mental Health",
          "description": "Resources for mental health and wellness"
        },
        {
          "name": "Nutrition & Diet",
          "description": "Information on nutrition, diets, and healthy eating"
        },
        {
          "name": "Exercise & Fitness",
          "description": "Workout routines, fitness tips, and exercise guides"
        },
        {
          "name": "Alternative Medicine",
          "description": "Resources on alternative and holistic medicine"
        }
      ]
    },
    {
      "name": "Miscellaneous",
      "description": "Miscellaneous resources that don't fit into other categories",
      "children": [
        {
          "name": "Fun & Humor",
          "description": "Websites for fun, humor, and memes"
        },
        {
          "name": "Puzzles & Brain Teasers",
          "description": "Online puzzles, riddles, and brain teasers"
        },
        {
          "name": "Quizzes & Trivia",
          "description": "Quizzes, trivia games, and knowledge tests"
        },
        {
          "name": "Random Generators",
          "description": "Tools that generate random content or ideas"
        }
      ]
    },
    {
      "name": "Uncategorized",
      "description": "Uncategorized favorites"
    }
  ]
}


---

File: server\folders_router.py

# folders_router.py

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from typing import List

from database import get_db
import schemas
from services import folder_service

router = APIRouter()

@router.post("/", response_model=schemas.Folder)
def create_folder(folder: schemas.FolderCreate, db: Session = Depends(get_db)):
    return folder_service.create_folder(db, folder)

@router.get("/{folder_id}/favorites", response_model=List[schemas.Favorite])
def get_folder_favorites(folder_id: int, skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    favorites = folder_service.get_folder_favorites(db, folder_id, skip, limit)
    if favorites is None:
        raise HTTPException(status_code=404, detail="Folder not found")
    return favorites

@router.get("/", response_model=List[dict])
def read_folders(db: Session = Depends(get_db)):
    return folder_service.get_folder_structure(db)

@router.put("/{folder_id}", response_model=schemas.Folder)
def update_folder(folder_id: int, folder: schemas.FolderCreate, db: Session = Depends(get_db)):
    updated_folder = folder_service.update_folder(db, folder_id, folder)
    if updated_folder is None:
        raise HTTPException(status_code=404, detail="Folder not found")
    return updated_folder

@router.delete("/{folder_id}", response_model=schemas.Folder)
def delete_folder(folder_id: int, move_to_parent: bool = False, db: Session = Depends(get_db)):
    deleted_folder = folder_service.delete_folder(db, folder_id, move_to_parent)
    if deleted_folder is None:
        raise HTTPException(status_code=404, detail="Folder not found")
    return deleted_folder

@router.post("/{folder_id}/move", response_model=schemas.Folder)
def move_folder(folder_id: int, new_parent_id: int, db: Session = Depends(get_db)):
    moved_folder = folder_service.move_folder(db, folder_id, new_parent_id)
    if moved_folder is None:
        raise HTTPException(status_code=404, detail="Folder not found")
    return moved_folder

@router.get("/{folder_id}/favorites", response_model=List[schemas.Favorite])
def get_folder_favorites(folder_id: int, skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    favorites = folder_service.get_folder_favorites(db, folder_id, skip, limit)
    if favorites is None:
        raise HTTPException(status_code=404, detail="Folder not found")
    return favorites

---

File: server\initDB.py

import json
from sqlalchemy import create_engine, inspect, text
from sqlalchemy.orm import sessionmaker
from database import Base, engine
from models import Folder, Favorite, Tag, Task, FavoriteToProcess, favorite_tags

# Initialize SQLAlchemy
engine = create_engine('sqlite:///favorites.db', echo=True)
Session = sessionmaker(bind=engine)
session = Session()

def clear_non_embedding_tables():
    # Get all table names
    inspector = inspect(engine)
    all_tables = inspector.get_table_names()

    # Tables to keep (related to vector embeddings)
    tables_to_keep = []  # We're not keeping any tables now, as favorites_embeddings is not in SQLite

    # Drop tables not related to embeddings
    for table in all_tables:
        if table not in tables_to_keep:
            session.execute(text(f"DELETE FROM {table}"))
            print(f"Cleared table: {table}")

    session.commit()
    print("Cleared all non-embedding tables.")

    # Recreate tables (this step is necessary if any tables were completely dropped)
    Base.metadata.create_all(engine)
    print("Ensured all tables exist.")

def create_folder(name, parent=None, description=None):
    folder = Folder(name=name, description=description)
    if parent:
        folder.parent = parent
    session.add(folder)
    session.flush()  # This will assign an ID to the folder
    return folder

def create_folder_structure(structure, parent=None):
    folder = create_folder(structure['name'], parent, structure.get('description'))
    for child in structure.get('children', []):
        create_folder_structure(child, folder)

def print_folder_structure(folder, level=0):
    print("  " * level + f"- {folder.name}")
    for child in folder.children:
        print_folder_structure(child, level + 1)

if __name__ == "__main__":
    print("Clearing non-embedding tables...")
    clear_non_embedding_tables()

    print("\nCreating initial folders...")
    # Load folder structure from JSON file
    with open('folder_structure.json', 'r') as f:
        folder_structure = json.load(f)

    # Create folder structure
    create_folder_structure(folder_structure)
    session.commit()

    print("Initial folders created successfully.")

    # Verify folder structure
    root = session.query(Folder).filter(Folder.name == "Favorites").first()
    print("\nFolder structure:")
    print_folder_structure(root)

    session.close()
    print("\nDatabase setup complete.")

---

File: server\llm.py

from abc import ABC, abstractmethod
import ollama
from openai import OpenAI
import os
from typing import Optional, Generator, Any
from anthropic import Anthropic, AsyncAnthropic, RateLimitError, APIStatusError, APIConnectionError
import logging

logger = logging.getLogger(__name__)

class LLMProvider(ABC):
    @abstractmethod
    def generate(self, prompt: str) -> str:
        pass

    @abstractmethod
    def generate_stream(self, prompt: str) -> Generator[str, None, None]:
        pass

class OllamaProvider(LLMProvider):
    def __init__(self, model: str = 'phi3.5'):
        self.model = model

    def generate(self, prompt: str) -> str:
        try:
            response = ollama.generate(model=self.model, prompt=prompt)
            return response['response']
        except Exception as e:
            raise RuntimeError(f"Error generating response with Ollama: {str(e)}")

    def generate_stream(self, prompt: str) -> Generator[str, None, None]:
        try:
            stream = ollama.generate(model=self.model, prompt=prompt, stream=True)
            for chunk in stream:
                yield chunk['response']
        except Exception as e:
            raise RuntimeError(f"Error generating streaming response with Ollama: {str(e)}")

class OpenAIProvider(LLMProvider):
    def __init__(self, model: str = "gpt-3.5-turbo"):
        self.model = model
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.")
        self.client = OpenAI()

    def generate(self, prompt: str) -> str:
        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}]
            )
            return completion.choices[0].message.content
        except Exception as e:
            raise RuntimeError(f"Error generating response with OpenAI: {str(e)}")

    def generate_stream(self, prompt: str) -> Generator[str, None, None]:
        try:
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                stream=True
            )
            for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        except Exception as e:
            raise RuntimeError(f"Error generating streaming response with OpenAI: {str(e)}")

    def generate_with_metadata(self, prompt: str) -> tuple[str, Any]:
        try:
            response = self.client.chat.completions.with_raw_response.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}]
            )
            completion = response.parse()
            return completion.choices[0].message.content, response.request_id
        except Exception as e:
            raise RuntimeError(f"Error generating response with metadata from OpenAI: {str(e)}")

import time
from anthropic import Anthropic, RateLimitError, APIStatusError, APIConnectionError

# llm.py

import os
import logging
from typing import Optional, Generator, Any
from anthropic import Anthropic, AsyncAnthropic, RateLimitError, APIStatusError, APIConnectionError
import httpx

logger = logging.getLogger(__name__)

class AnthropicProvider(LLMProvider):
    def __init__(self, model: str = "claude-3-haiku-20240307"):
        self.model = model
        self.initialize_client()

    def initialize_client(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("Anthropic API key not found. Please set the ANTHROPIC_API_KEY environment variable.")
        self.client = Anthropic(
            max_retries=3,
            timeout=httpx.Timeout(30.0, connect=5.0)
        )

    def generate(self, prompt: str) -> str:
        try:
            message = self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
            )
            return message.content[0].text
        except RateLimitError as e:
            logger.warning(f"Rate limit reached: {str(e)}")
            raise
        except APIConnectionError as e:
            logger.error(f"Connection error: {str(e)}")
            raise
        except APIStatusError as e:
            logger.error(f"API error: {e.status_code} - {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error generating response: {str(e)}")
            raise

    def generate_stream(self, prompt: str) -> Generator[str, None, None]:
        try:
            stream = self.client.messages.create(
                model=self.model,
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
                stream=True,
            )
            for event in stream:
                if event.type == "content_block_delta":
                    yield event.delta.text
        except RateLimitError as e:
            logger.warning(f"Rate limit reached in stream: {str(e)}")
            raise
        except APIConnectionError as e:
            logger.error(f"Connection error in stream: {str(e)}")
            raise
        except APIStatusError as e:
            logger.error(f"API error in stream: {e.status_code} - {str(e)}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error generating streaming response: {str(e)}")
            raise
class LLMService:
    def __init__(self, provider: Optional[LLMProvider] = None):
        if provider is None:
            # Default to Ollama if no provider is specified
            provider = OllamaProvider()
        self.provider = provider

    def generate(self, prompt: str) -> str:
        return self.provider.generate(prompt)

    def generate_stream(self, prompt: str) -> Generator[str, None, None]:
        return self.provider.generate_stream(prompt)

    def generate_with_metadata(self, prompt: str) -> tuple[str, Any]:
        if isinstance(self.provider, OpenAIProvider):
            return self.provider.generate_with_metadata(prompt)
        else:
            return self.generate(prompt), None

# Initialize with default provider (Ollama)
# llm_service = LLMService()

# To use OpenAI provider, uncomment the following line and ensure OPENAI_API_KEY is set
# llm_service = LLMService(OpenAIProvider())

# To use Anthropic provider, uncomment the following line and ensure ANTHROPIC_API_KEY is set
llm_service = LLMService(AnthropicProvider())

---

File: server\models.py

from sqlalchemy import Column, Integer, String, ForeignKey, Table, DateTime, Text, Boolean, JSON
from sqlalchemy.orm import relationship
from datetime import datetime, timezone
from sqlalchemy.sql import func
from database import Base

# Association table for many-to-many relationship between Favorite and Tag
favorite_tags = Table('favorite_tags', Base.metadata,
    Column('favorite_id', Integer, ForeignKey('favorites.id'), primary_key=True),
    Column('tag_id', Integer, ForeignKey('tags.id'), primary_key=True)
)

class Folder(Base):
    __tablename__ = 'folders'

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False)
    parent_id = Column(Integer, ForeignKey('folders.id'))
    description = Column(String)
    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))

    parent = relationship('Folder', remote_side=[id], back_populates='children')
    children = relationship('Folder', back_populates='parent')
    favorites = relationship('Favorite', back_populates='folder')

class Favorite(Base):
    __tablename__ = 'favorites'

    id = Column(Integer, primary_key=True, index=True)
    url = Column(String, nullable=False)
    title = Column(String)
    summary = Column(Text)
    folder_id = Column(Integer, ForeignKey('folders.id'))
    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))

    folder = relationship('Folder', back_populates='favorites')
    tags = relationship('Tag', secondary=favorite_tags, back_populates='favorites')

class Tag(Base):
    __tablename__ = 'tags'

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False, unique=True)

    favorites = relationship('Favorite', secondary=favorite_tags, back_populates='tags')

class FavoriteToProcess(Base):
    __tablename__ = 'favorites_to_process'

    id = Column(Integer, primary_key=True, index=True)
    url = Column(String, nullable=False)
    title = Column(String)
    metainfo = Column(String)
    processed = Column(Boolean, default=False)
    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))

class Task(Base):
    __tablename__ = 'tasks'

    id = Column(String, primary_key=True)
    name = Column(String, nullable=False)
    status = Column(String, nullable=False)
    progress = Column(String, nullable=False)
    result = Column(Text)
    created_at = Column(DateTime, default=lambda: datetime.now(timezone.utc))
    updated_at = Column(DateTime, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc))

---

File: server\schemas.py

from pydantic import BaseModel, HttpUrl
from typing import List, Optional
from datetime import datetime

# Schemas for Tag
class TagBase(BaseModel):
    name: str

class TagCreate(TagBase):
    pass

class Tag(TagBase):
    id: int

    class Config:
        from_attributes = True

# Schemas for Folder
class FolderBase(BaseModel):
    name: str
    description: Optional[str] = None

class FolderCreate(FolderBase):
    parent_id: Optional[int] = None

class Folder(FolderBase):
    id: int
    parent_id: Optional[int]
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True

# Schemas for Favorite
class FavoriteBase(BaseModel):
    url: HttpUrl
    title: Optional[str] = None
    summary: Optional[str] = None

class FavoriteCreate(FavoriteBase):
    folder_id: Optional[int] = None
    tags: Optional[List[str]] = None
    metadata: Optional[str] = None  # Include metadata for creation, but don't persist it

class FavoriteUpdate(BaseModel):
    title: Optional[str] = None
    summary: Optional[str] = None
    folder_id: Optional[int] = None
    tags: Optional[List[str]] = None

class Favorite(FavoriteBase):
    id: int
    folder_id: Optional[int]
    created_at: datetime
    updated_at: datetime
    tags: List[Tag] = []

    class Config:
        from_attributes = True

# Schemas for nested relationships
class FolderWithChildren(Folder):
    children: List['FolderWithChildren'] = []
    favorites: List[Favorite] = []

    class Config:
        from_attributes = True

class TaskStatus(BaseModel):
    id: str
    name: str
    status: str
    progress: str

class TaskStatusDetail(TaskStatus):
    result: Optional[str] = None

class TaskCreate(BaseModel):
    name: str

class FavoriteImport(BaseModel):
    url: HttpUrl
    title: str
    metadata: Optional[str] = None

FolderWithChildren.model_rebuild()

---

File: server\services.py

# services.py
from sqlalchemy import func
from sqlalchemy.orm import Session, joinedload
from sqlalchemy.exc import IntegrityError
import models, schemas
from typing import List, Optional
import requests
from bs4 import BeautifulSoup
import logging
from threading import Thread
import re
from typing import Union
from task_queue import task_queue
from database import SessionLocal, engine
import asyncio
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import random
from urllib.parse import urlparse
from llm import llm_service
from rich import print as rprint
import builtins
import json
from jinja2 import Environment, FileSystemLoader
import os
from content_extractor import ContentExtractor
from typing import List
import math
from vector_store import vector_store

builtins.print = rprint

logger = logging.getLogger(__name__)


class FavoriteService:
    async def create_favorite_task(self, task_id: str, favorite_data: dict):
        db = SessionLocal()
        try:
            favorite = schemas.FavoriteCreate(**favorite_data)
            
            task_queue._update_task(task_id, "processing", 10, None)
            # Generate summary if not provided
            if not favorite.summary:
                favorite.summary = await nlp_service.summarize_content(str(favorite.url), favorite.metadata)
            
            task_queue._update_task(task_id, "processing", 40, None)
            # Suggest tags if not provided
            if not favorite.tags:
                favorite.tags = await nlp_service.suggest_tags(favorite.summary, favorite.metadata)
            
            task_queue._update_task(task_id, "processing", 70, None)
            # Suggest folder if not provided
            if not favorite.folder_id:
                favorite.folder_id = await nlp_service.suggest_folder(db, favorite.summary, favorite.metadata)
            
            # Prepare the favorite data
            favorite_data = {
                "url": str(favorite.url),
                "title": favorite.title,
                "summary": favorite.summary,
                "folder_id": favorite.folder_id
            }

            # Try to get existing favorite or create a new one
            db_favorite = db.query(models.Favorite).filter(models.Favorite.url == str(favorite.url)).first()
            if db_favorite:
                # Update existing favorite
                for key, value in favorite_data.items():
                    setattr(db_favorite, key, value)
            else:
                # Create new favorite
                db_favorite = models.Favorite(**favorite_data)
                db.add(db_favorite)

            db.flush()

            for tag_name in favorite.tags:
                tag = db.query(models.Tag).filter(models.Tag.name == tag_name).first()
                if not tag:
                    tag = models.Tag(name=tag_name)
                    db.add(tag)
                    db.flush()
                db_favorite.tags.append(tag)

            db.commit()

            # Add or update the favorite in the vector store
            vector_store.add_favorite(db_favorite.id, db_favorite.url, db_favorite.title, db_favorite.summary)

            return db_favorite.id
        except Exception as e:
            logger.error(f"Error creating favorite: {str(e)}")
            db.rollback()
            raise
        finally:
            db.close()

    def _run_task_wrapper(self, task_id, task_func):
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(task_func(task_id))
            task_queue._update_task(task_id, "completed", "100", result)
        except Exception as e:
            logger.error(f"Error in _run_task_wrapper: {str(e)}", exc_info=True)
            task_queue._update_task(task_id, "failed", "0", str(e))
        finally:
            loop.close()

    def get_favorites_by_ids(self, db: Session, favorite_ids: List[int]) -> List[models.Favorite]:
            return db.query(models.Favorite).filter(models.Favorite.id.in_(favorite_ids)).all()

    def create_favorite(self, favorite: schemas.FavoriteCreate, task_name: str):
        task_id = task_queue.add_task(
            self.create_favorite_task, task_name, favorite.dict()
        )
        return {"task_id": task_id}

    def get_favorite(self, db: Session, favorite_id: int) -> Optional[models.Favorite]:
        return (
            db.query(models.Favorite).filter(models.Favorite.id == favorite_id).first()
        )

    def get_favorites(
        self, db: Session, skip: int = 0, limit: int = 100
    ) -> List[models.Favorite]:
        return db.query(models.Favorite).offset(skip).limit(limit).all()

    def update_favorite(
        self, db: Session, favorite_id: int, favorite: schemas.FavoriteUpdate
    ) -> Optional[models.Favorite]:
        db_favorite = (
            db.query(models.Favorite).filter(models.Favorite.id == favorite_id).first()
        )
        if db_favorite:
            update_data = favorite.model_dump(exclude_unset=True)
            
            # Handle tags separately
            if 'tags' in update_data:
                new_tags = update_data.pop('tags')
                # Clear existing tags
                db_favorite.tags.clear()
                # Add new tags
                for tag_name in new_tags:
                    tag = db.query(models.Tag).filter(models.Tag.name == tag_name).first()
                    if not tag:
                        tag = models.Tag(name=tag_name)
                        db.add(tag)
                    db_favorite.tags.append(tag)
            
            # Update other fields
            for key, value in update_data.items():
                setattr(db_favorite, key, value)
            
            db.commit()
            db.refresh(db_favorite)

            # Update the favorite in the vector store
            vector_store.update_favorite(db_favorite.id, db_favorite.url, db_favorite.title, db_favorite.summary)

        return db_favorite

    def delete_favorite(
        self, db: Session, favorite_id: int
    ) -> Optional[models.Favorite]:
        db_favorite = (
            db.query(models.Favorite).filter(models.Favorite.id == favorite_id).first()
        )
        if db_favorite:
            db.delete(db_favorite)
            db.commit()

            # Delete the favorite from the vector store
            vector_store.delete_favorite(favorite_id)
            
        return db_favorite

    async def delete_all_favorites_task(self, task_id: str):
        db = SessionLocal()
        try:
            task_queue._update_task(task_id, "processing", 10, None)
            
            # Delete all favorites
            db.query(models.Favorite).delete()
            db.commit()
            
            task_queue._update_task(task_id, "processing", 90, None)
            
            return "All favorites deleted successfully"
        except Exception as e:
            logger.error(f"Error deleting all favorites: {str(e)}")
            db.rollback()
            raise
        finally:
            db.close()

    def delete_all_favorites(self, task_name: str):
        task_id = task_queue.add_task(
            self.delete_all_favorites_task, task_name
        )
        return {"task_id": task_id}

    async def import_favorites_task(self, task_id: str, favorites: List[schemas.FavoriteImport]):
        db = SessionLocal()
        try:
            total_favorites = len(favorites)
            
            # Store all favorites to process
            for favorite in favorites:
                db_favorite_to_process = models.FavoriteToProcess(
                    url=str(favorite.url),
                    title=favorite.title,
                    metainfo=favorite.metadata
                )
                db.add(db_favorite_to_process)
            db.commit()

            # Process favorites
            processed_count = 0
            for favorite_to_process in db.query(models.FavoriteToProcess).filter(models.FavoriteToProcess.processed == False).all():
                try:
                    summary = await nlp_service.summarize_content(str(favorite_to_process.url), favorite_to_process.metainfo)
                    suggested_tags = await nlp_service.suggest_tags(summary, favorite_to_process.metainfo)
                    suggested_folder_id = await nlp_service.suggest_folder(db, summary, favorite_to_process.metainfo)
                    
                    db_favorite = models.Favorite(
                        url=favorite_to_process.url,
                        title=favorite_to_process.title,
                        summary=summary,
                        folder_id=suggested_folder_id
                    )
                    db.add(db_favorite)
                    db.flush()

                    for tag_name in suggested_tags:
                        tag = db.query(models.Tag).filter(models.Tag.name == tag_name).first()
                        if not tag:
                            tag = models.Tag(name=tag_name)
                            db.add(tag)
                            db.flush()
                        db_favorite.tags.append(tag)

                    db.commit()

                except Exception as e:
                    logger.error(f"Error processing favorite {favorite_to_process.url}: {str(e)}")
                    db.rollback()

                finally:
                    # Delete the processed favorite from FavoriteToProcess, regardless of success or failure
                    db.delete(favorite_to_process)
                    db.commit()

                    processed_count += 1
                    progress = int((processed_count / total_favorites) * 100)
                    task_queue._update_task(task_id, "processing", str(progress), None)

                # Add a small delay between processing favorites
                await asyncio.sleep(1)

            return f"Successfully processed {processed_count} out of {total_favorites} favorites"
        except Exception as e:
            logger.error(f"Error importing favorites: {str(e)}")
            raise
        finally:
            db.close()

    def import_favorites(self, favorites: List[schemas.FavoriteImport], task_name: str):
        task_id = task_queue.add_task(
            self.import_favorites_task, task_name, favorites
        )
        return {"task_id": task_id}
    
    async def restart_import_task(self, task_name: str):
        db = SessionLocal()
        try:
            # Find the restartable task
            restartable_task = db.query(models.Task).filter(models.Task.status == "restartable").first()
            if restartable_task:
                # Update its status to processing
                restartable_task.status = "processing"
                db.commit()
                
                # Start processing remaining favorites without creating a new task
                Thread(target=self._run_task_wrapper, args=(restartable_task.id, self.process_remaining_favorites)).start()
                
                return {"task_id": restartable_task.id}
            else:
                # If no restartable task exists, create a new one (this should not happen in your scenario)
                logger.warning("No restartable task found when trying to restart import.")
                task_id = task_queue.add_task(
                    self.process_remaining_favorites, task_name
                )
                return {"task_id": task_id}
        finally:
            db.close()

    async def process_remaining_favorites(self, task_id: str):
        db = SessionLocal()
        try:
            total_favorites = db.query(models.FavoriteToProcess).filter(models.FavoriteToProcess.processed == False).count()
            processed_count = 0

            for favorite_to_process in db.query(models.FavoriteToProcess).filter(models.FavoriteToProcess.processed == False).all():
                try:
                    summary = await nlp_service.summarize_content(str(favorite_to_process.url), favorite_to_process.metadata)
                    suggested_tags = await nlp_service.suggest_tags(summary, favorite_to_process.metadata)
                    suggested_folder_id = await nlp_service.suggest_folder(db, summary, favorite_to_process.metadata)
                    
                    db_favorite = models.Favorite(
                        url=favorite_to_process.url,
                        title=favorite_to_process.title,
                        summary=summary,
                        folder_id=suggested_folder_id
                    )
                    db.add(db_favorite)
                    db.flush()

                    for tag_name in suggested_tags:
                        tag = db.query(models.Tag).filter(models.Tag.name == tag_name).first()
                        if not tag:
                            tag = models.Tag(name=tag_name)
                            db.add(tag)
                            db.flush()
                        db_favorite.tags.append(tag)

                    favorite_to_process.processed = True
                    db.commit()

                    processed_count += 1
                    progress = int((processed_count / total_favorites) * 100)
                    task_queue._update_task(task_id, "processing", str(progress), None)

                except Exception as e:
                    logger.error(f"Error processing favorite {favorite_to_process.url}: {str(e)}")
                    db.rollback()

                # Add a small delay between processing favorites
                await asyncio.sleep(1)

            return f"Successfully processed {processed_count} out of {total_favorites} remaining favorites"
        except Exception as e:
            logger.error(f"Error processing remaining favorites: {str(e)}")
            raise
        finally:
            db.close()

class FolderService:
    def create_folder(self, db: Session, folder: schemas.FolderCreate) -> models.Folder:
        db_folder = models.Folder(**folder.dict())
        db.add(db_folder)
        db.commit()
        db.refresh(db_folder)
        return db_folder

    def get_folder(self, db: Session, folder_id: int) -> Optional[models.Folder]:
        return db.query(models.Folder).filter(models.Folder.id == folder_id).first()

    def get_folders(
        self, db: Session, skip: int = 0, limit: int = 100
    ) -> List[models.Folder]:
        return (
            db.query(models.Folder)
            .filter(models.Folder.parent_id == None)
            .options(joinedload(models.Folder.children))
            .offset(skip)
            .limit(limit)
            .all()
        )

    def update_folder(
        self, db: Session, folder_id: int, folder: schemas.FolderCreate
    ) -> Optional[models.Folder]:
        db_folder = (
            db.query(models.Folder).filter(models.Folder.id == folder_id).first()
        )
        if db_folder:
            for key, value in folder.dict().items():
                setattr(db_folder, key, value)
            db.commit()
            db.refresh(db_folder)
        return db_folder

    def delete_folder(
        self, db: Session, folder_id: int, move_to_parent: bool = False
    ) -> Optional[models.Folder]:
        db_folder = (
            db.query(models.Folder).filter(models.Folder.id == folder_id).first()
        )
        if db_folder:
            if move_to_parent and db_folder.parent_id:
                for child_folder in db_folder.children:
                    child_folder.parent_id = db_folder.parent_id
                for favorite in db_folder.favorites:
                    favorite.folder_id = db_folder.parent_id
            else:
                for child_folder in db_folder.children:
                    child_folder.parent_id = None
                for favorite in db_folder.favorites:
                    favorite.folder_id = None
            db.delete(db_folder)
            db.commit()
        return db_folder

    def get_folder_structure(self, db: Session):
        def build_structure(folder):
            return {
                "id": folder.id,
                "name": folder.name,
                "parent_id": folder.parent_id,
                "description": folder.description,
                "children": [
                    build_structure(child)
                    for child in folder.children
                    if isinstance(child, models.Folder)
                ],
            }

        root_folders = (
            db.query(models.Folder)
            .filter(models.Folder.parent_id == None)
            .options(joinedload(models.Folder.children))
            .all()
        )
        return [build_structure(folder) for folder in root_folders]

    def get_folder_favorites(
        self, db: Session, folder_id: int, skip: int = 0, limit: int = 100
    ):
        folder = db.query(models.Folder).filter(models.Folder.id == folder_id).first()
        if folder:
            return (
                db.query(models.Favorite)
                .filter(models.Favorite.folder_id == folder_id)
                .offset(skip)
                .limit(limit)
                .all()
            )
        return None


class TagService:
    def create_tag(self, db: Session, tag: schemas.TagCreate) -> models.Tag:
        db_tag = models.Tag(**tag.dict())
        db.add(db_tag)
        db.commit()
        db.refresh(db_tag)
        return db_tag

    def get_tag(self, db: Session, tag_id: int) -> Optional[models.Tag]:
        return db.query(models.Tag).filter(models.Tag.id == tag_id).first()

    def get_tags(
        self, db: Session, skip: int = 0, limit: int = 100
    ) -> List[models.Tag]:
        return db.query(models.Tag).offset(skip).limit(limit).all()

    def update_tag(
        self, db: Session, tag_id: int, tag: schemas.TagCreate
    ) -> Optional[models.Tag]:
        db_tag = db.query(models.Tag).filter(models.Tag.id == tag_id).first()
        if db_tag:
            for key, value in tag.dict().items():
                setattr(db_tag, key, value)
            db.commit()
            db.refresh(db_tag)
        return db_tag

    def delete_tag(self, db: Session, tag_id: int) -> Optional[models.Tag]:
        db_tag = db.query(models.Tag).filter(models.Tag.id == tag_id).first()
        if db_tag:
            db.delete(db_tag)
            db.commit()
        return db_tag

    def search_tags(self, db: Session, query: str) -> List[models.Tag]:
        return db.query(models.Tag).filter(models.Tag.name.ilike(f"%{query}%")).all()

    def get_tag_favorites(
        self, db: Session, tag_id: int, skip: int = 0, limit: int = 100
    ) -> Optional[List[models.Favorite]]:
        tag = self.get_tag(db, tag_id)
        if tag:
            return tag.favorites[skip : skip + limit]
        return None

    async def suggest_tags(self, content: str) -> List[str]:
        return await nlp_service.suggest_tags(content)

    def get_popular_tags(self, db: Session, limit: int = 10) -> List[models.Tag]:
        return (
            db.query(models.Tag)
            .join(models.favorite_tags)
            .group_by(models.Tag.id)
            .order_by(func.count(models.favorite_tags.c.favorite_id).desc())
            .limit(limit)
            .all()
        )
    
    def get_favorites_by_fuzzy_tag(self, db: Session, tag_query: str, skip: int = 0, limit: int = 100) -> List[models.Favorite]:
        # Convert the query to lowercase and surround with wildcards
        fuzzy_query = f"%{tag_query.lower()}%"
        return (db.query(models.Favorite)
                  .join(models.favorite_tags)
                  .join(models.Tag)
                  .filter(func.lower(models.Tag.name).like(fuzzy_query))
                  .offset(skip)
                  .limit(limit)
                  .all())

class NLPService:
    def __init__(self):
        self.session = requests.Session()
        retries = Retry(
            total=5, backoff_factor=0.1, status_forcelist=[500, 502, 503, 504]
        )
        self.session.mount("http://", HTTPAdapter(max_retries=retries))
        self.session.mount("https://", HTTPAdapter(max_retries=retries))

        # Set up Jinja2 environment
        template_dir = os.path.join(os.path.dirname(__file__), "templates")
        self.jinja_env = Environment(loader=FileSystemLoader(template_dir))

        # Initialize ContentExtractor
        self.content_extractor = ContentExtractor(self.fetch_with_retries)

    def get_random_user_agent(self):
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59",
        ]
        return random.choice(user_agents)

    async def fetch_with_retries(self, url, max_retries=3):
        for attempt in range(max_retries):
            headers = {
                "User-Agent": self.get_random_user_agent(),
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                "Accept-Language": "en-US,en;q=0.5",
                "Referer": "https://www.google.com/",
                "DNT": "1",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }

            try:
                await asyncio.sleep(random.uniform(1, 3))  # Random delay
                response = await asyncio.to_thread(
                    self.session.get, url, headers=headers, timeout=15
                )
                response.raise_for_status()
                return response
            except requests.HTTPError as e:
                if e.response.status_code == 403:
                    logger.warning(
                        f"403 Forbidden encountered on attempt {attempt + 1}. Retrying..."
                    )
                    if attempt == max_retries - 1:
                        logger.error(
                            f"Max retries reached for URL {url}. Unable to fetch content."
                        )
                        raise
                else:
                    raise
            except requests.RequestException as e:
                logger.error(
                    f"Error fetching URL {url} on attempt {attempt + 1}: {str(e)}"
                )
                if attempt == max_retries - 1:
                    raise

    def generate_fallback_description(self, url: str, metadata: str) -> str:
        parsed_url = urlparse(url)
        domain = parsed_url.netloc
        path = parsed_url.path

        template = self.jinja_env.get_template("generate_fallback_description.j2")
        prompt = template.render(url=url, metadata=metadata)

        return llm_service.generate(prompt)

    async def summarize_content(self, url: str, metadata: str) -> str:
        try:
            content = await self.content_extractor.extract_content(url)

            template = self.jinja_env.get_template("summarize_content.j2")
            prompt = template.render(metadata=metadata, content=content)

            return llm_service.generate(prompt)

        except requests.RequestException as e:
            logger.error(f"Error fetching URL {url}: {str(e)}")
            return self.generate_fallback_description(url, metadata)
        except Exception as e:
            logger.error(f"Unexpected error while summarizing content for {url}: {str(e)}")
            raise

    async def suggest_tags(self, summary: str, metadata: str) -> List[str]:
        try:
            template = self.jinja_env.get_template("suggest_tags.j2")
            prompt = template.render(summary=summary, metadata=metadata)

            response = llm_service.generate(prompt)
            cleaned_response = response.split("\n")[0]
            tags = cleaned_response.split(",")

            formatted_tags = []
            for tag in tags:
                tag = tag.strip()
                if tag:
                    tag = tag.replace("-", " ").replace("_", " ")
                    if tag[0].isalpha():
                        tag = tag[0].upper() + tag[1:]
                    formatted_tags.append(tag)

            return formatted_tags

        except Exception as e:
            logger.error(f"Unexpected error while suggesting tags: {str(e)}")
            raise

    def get_folder_structure(self, db: Session):
        def build_structure(folder, level=0):
            return {
                "name": folder.name,
                "id": folder.id,
                "level": level,
                "children": [
                    build_structure(child, level + 1) for child in folder.children
                ],
            }

        root = db.query(models.Folder).filter(models.Folder.parent_id == None).first()
        return build_structure(root)

    def format_folder_structure(self, structure, level=0):
        result = "  " * level + f"- {structure['name']} (ID: {structure['id']})\n"
        for child in structure["children"]:
            result += self.format_folder_structure(child, level + 1)
        return result

    async def suggest_folder(self, db: Session, summary: str, metadata: str) -> int:
        try:
            folder_structure = self.get_folder_structure(db)
            formatted_structure = self.format_folder_structure(folder_structure)

            template = self.jinja_env.get_template("suggest_folder.j2")
            prompt = template.render(
                summary=summary, metadata=metadata, formatted_structure=formatted_structure
            )

            suggestion = llm_service.generate(prompt)
            suggestion_json = json.loads(suggestion)

            parent_folder_id = suggestion_json.get("id")
            suggested_folder = suggestion_json["children"][0]

            parent_folder = db.query(models.Folder).filter(models.Folder.id == parent_folder_id).first()
            if not parent_folder:
                logger.warning(f"Suggested parent folder ID {parent_folder_id} does not exist. Using root folder.")
                parent_folder_id = folder_structure["id"]

            if "id" in suggested_folder:
                existing_folder = db.query(models.Folder).filter(models.Folder.id == suggested_folder["id"]).first()
                if existing_folder:
                    return existing_folder.id
                else:
                    logger.warning(f"Suggested folder ID {suggested_folder['id']} does not exist. Creating a new folder.")

            return self.create_new_folder(db, parent_folder_id, suggested_folder["name"])

        except json.JSONDecodeError:
            logger.error(f"Failed to parse LLM response as JSON: {suggestion}")
            return self.get_or_create_uncategorized_folder(db)
        except Exception as e:
            logger.error(f"Unexpected error while suggesting folder: {str(e)}")
            return self.get_or_create_uncategorized_folder(db)


    def create_new_folder(self, db: Session, parent_id: int, folder_name: str) -> int:
        try:
            db_folder = models.Folder(name=folder_name, parent_id=parent_id)
            db.add(db_folder)
            db.commit()
            db.refresh(db_folder)
            logger.info(f"Created new folder: {db_folder.name} (ID: {db_folder.id})")
            return db_folder.id
        except Exception as e:
            logger.error(f"Error creating new folder: {str(e)}")
            db.rollback()
            return self.get_or_create_uncategorized_folder(db)

    def get_or_create_uncategorized_folder(self, db: Session) -> int:
        try:
            uncategorized = (
                db.query(models.Folder)
                .filter(models.Folder.name == "Uncategorized")
                .first()
            )
            if not uncategorized:
                uncategorized = models.Folder(name="Uncategorized", parent_id=None)
                db.add(uncategorized)
                db.commit()
                db.refresh(uncategorized)
                logger.info(f"Created Uncategorized folder (ID: {uncategorized.id})")
            return uncategorized.id
        except Exception as e:
            logger.error(f"Error getting or creating Uncategorized folder: {str(e)}")
            db.rollback()
            # If all else fails, return None or a default folder ID
            return None  # or return a default folder ID if you have one


# Initialize services
favorite_service = FavoriteService()
folder_service = FolderService()
tag_service = TagService()
nlp_service = NLPService()


---

File: server\tags_router.py

# tags_router.py

from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from typing import List
from urllib.parse import unquote
from database import get_db
import schemas
from services import tag_service

router = APIRouter()

@router.post("/", response_model=schemas.Tag)
def create_tag(tag: schemas.TagCreate, db: Session = Depends(get_db)):
    return tag_service.create_tag(db, tag)

@router.get("/{tag_id}", response_model=schemas.Tag)
def read_tag(tag_id: int, db: Session = Depends(get_db)):
    db_tag = tag_service.get_tag(db, tag_id)
    if db_tag is None:
        raise HTTPException(status_code=404, detail="Tag not found")
    return db_tag

@router.get("/", response_model=List[schemas.Tag])
def read_tags(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    return tag_service.get_tags(db, skip=skip, limit=limit)

@router.put("/{tag_id}", response_model=schemas.Tag)
def update_tag(tag_id: int, tag: schemas.TagCreate, db: Session = Depends(get_db)):
    updated_tag = tag_service.update_tag(db, tag_id, tag)
    if updated_tag is None:
        raise HTTPException(status_code=404, detail="Tag not found")
    return updated_tag

@router.delete("/{tag_id}", response_model=schemas.Tag)
def delete_tag(tag_id: int, db: Session = Depends(get_db)):
    deleted_tag = tag_service.delete_tag(db, tag_id)
    if deleted_tag is None:
        raise HTTPException(status_code=404, detail="Tag not found")
    return deleted_tag

@router.get("/search/{query}", response_model=List[schemas.Tag])
def search_tags(query: str, db: Session = Depends(get_db)):
    return tag_service.search_tags(db, query)

@router.get("/{tag_id}/favorites", response_model=List[schemas.Favorite])
def get_tag_favorites(tag_id: int, skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):
    favorites = tag_service.get_tag_favorites(db, tag_id, skip, limit)
    if favorites is None:
        raise HTTPException(status_code=404, detail="Tag not found")
    return favorites

@router.post("/suggest", response_model=List[str])
async def suggest_tags(content: str, db: Session = Depends(get_db)):
    return await tag_service.suggest_tags(content)

@router.get("/popular", response_model=List[schemas.Tag])
def get_popular_tags(limit: int = 10, db: Session = Depends(get_db)):
    return tag_service.get_popular_tags(db, limit)

@router.get("/fuzzy/{tag_query}/favorites", response_model=List[schemas.Favorite])
def get_favorites_by_fuzzy_tag(
    tag_query: str,
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=100),
    db: Session = Depends(get_db)
):
    # Decode the URL-encoded query and remove any remaining '%' characters
    decoded_query = unquote(tag_query).replace('%', '')
    favorites = tag_service.get_favorites_by_fuzzy_tag(db, decoded_query, skip, limit)
    if not favorites:
        raise HTTPException(status_code=404, detail="No favorites found for the given tag query")
    return favorites

---

File: server\task_queue.py

from sqlalchemy import Column, String, JSON, DateTime, inspect, text
from sqlalchemy.orm import Session
from database import Base, engine, SessionLocal
from threading import Thread
import asyncio
import uuid
import json
from datetime import datetime, timezone
from models import Task

class TaskQueue:
    def __init__(self):
        self.init_db()

    def init_db(self):
        inspector = inspect(engine)
        if not inspector.has_table("tasks"):
            Base.metadata.create_all(bind=engine)
        else:
            # Check if created_at column exists
            columns = [col['name'] for col in inspector.get_columns("tasks")]
            if 'created_at' not in columns:
                # Add created_at column
                with engine.connect() as conn:
                    conn.execute(text("ALTER TABLE tasks ADD COLUMN created_at DATETIME"))
                    conn.commit()

    def generate_task_id(self):
        return str(uuid.uuid4())
    
    def add_task(self, task_func, task_name, *args, **kwargs):
        task_id = str(uuid.uuid4())
        with SessionLocal() as db:
            db_task = Task(id=task_id, name=task_name, status="pending", progress="0", result=None, created_at=datetime.now(timezone.utc))
            db.add(db_task)
            db.commit()

        Thread(target=self._run_task, args=(task_id, task_func, args, kwargs)).start()
        return task_id

    def _run_task(self, task_id, task_func, args, kwargs):
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(task_func(task_id, *args, **kwargs))
            self._update_task(task_id, "completed", "100", result)
        except Exception as e:
            self._update_task(task_id, "failed", "0", str(e))
        finally:
            loop.close()

    def _update_task(self, task_id, status, progress, result):
        with SessionLocal() as db:
            task = db.query(Task).filter(Task.id == task_id).first()
            if task:
                task.status = status
                task.progress = progress
                task.result = result
                db.commit()

    def get_task_status(self, task_id):
        with SessionLocal() as db:
            task = db.query(Task).filter(Task.id == task_id).first()
        if task:
            return {
                "id": task.id,
                "name": task.name,
                "status": task.status,
                "progress": task.progress,
                "result": task.result
            }
        return None

    def get_all_tasks(self):
        with SessionLocal() as db:
            tasks = db.query(Task).order_by(Task.created_at.desc()).all()
        return [
            {
                "id": task.id,
                "name": task.name,
                "status": task.status,
                "progress": task.progress,
                "created_at": task.created_at.isoformat() if task.created_at else None
            } for task in tasks
        ]
    
    def get_restartable_tasks(self):
        with SessionLocal() as db:
            tasks = db.query(Task).filter(Task.status == "restartable").all()
        return [
            {
                "id": task.id,
                "name": task.name,
                "status": task.status,
                "progress": task.progress,
                "created_at": task.created_at.isoformat() if task.created_at else None
            } for task in tasks
        ]

task_queue = TaskQueue()

---

File: server\testCreate.py

import requests
from bs4 import BeautifulSoup
import time
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# API endpoint
API_URL = "http://localhost:8000/api/favorites/"

# List of tech-related websites with specific paths
TECH_WEBSITES = [
    "https://www.wired.com/category/artificial-intelligence/",
    "https://techcrunch.com/category/startups/",
    "https://www.theverge.com/tech",
    "https://arstechnica.com/gadgets/",
    "https://www.engadget.com/mobile/",
    "https://www.cnet.com/tech/computing/",
    "https://www.technologyreview.com/topic/artificial-intelligence/",
    "https://www.anandtech.com/tag/cpus",
    "https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html",
    "https://www.pcgamer.com/hardware/"
]

def get_webpage_title(url):
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        title = soup.title.string if soup.title else "No title found"
        return title.strip()
    except requests.RequestException as e:
        logging.error(f"Failed to fetch title for {url}. Error: {str(e)}")
        return "Error fetching title"

def generate_favorite(url):
    title = get_webpage_title(url)
    return {"url": url, "title": title}

def create_favorite(favorite):
    try:
        response = requests.post(API_URL, json=favorite)
        response.raise_for_status()
        logging.info(f"Successfully created favorite: {favorite['title']}")
        return response.json()
    except requests.exceptions.RequestException as e:
        logging.error(f"Failed to create favorite: {favorite['title']}. Error: {str(e)}")
        return None

def stress_test(num_favorites, delay):
    successful_creations = 0
    failed_creations = 0

    start_time = time.time()

    for i in range(num_favorites):
        url = TECH_WEBSITES[i % len(TECH_WEBSITES)]
        favorite = generate_favorite(url)
        result = create_favorite(favorite)
        
        if result:
            successful_creations += 1
        else:
            failed_creations += 1

        time.sleep(delay)

    end_time = time.time()
    total_time = end_time - start_time

    logging.info(f"\nStress test completed.")
    logging.info(f"Total favorites attempted: {num_favorites}")
    logging.info(f"Successful creations: {successful_creations}")
    logging.info(f"Failed creations: {failed_creations}")
    logging.info(f"Total time taken: {total_time:.2f} seconds")
    logging.info(f"Average time per request: {total_time/num_favorites:.2f} seconds")

if __name__ == "__main__":
    num_favorites = 10  # Reduced number for demonstration, adjust as needed
    delay = 1  # Increased delay to be more respectful to the websites

    logging.info(f"Starting stress test with {num_favorites} favorites and {delay} second delay between requests.")
    stress_test(num_favorites, delay)

---

File: server\templates\generate_fallback_description.j2

Generate a brief, general description for a webpage based on its URL and metadata. The information is:

URL: {{ url }}

Metadata:
{{ metadata }}

Your description should:
1. Identify the likely type of website (e.g., company website, blog, news site, etc.) based on the domain name and metadata.
2. Suggest possible content or purpose of the specific page based on the URL path and available metadata.
3. Use neutral language and avoid making definitive claims about the content unless clearly stated in the metadata.

Limit your response to 2-3 sentences.

---

File: server\templates\suggest_folder.j2

You are tasked with suggesting the most appropriate folder for a webpage based on its summary, metadata, and the existing folder structure. Follow these steps carefully:

1. First, you will be presented with a summary of a webpage and its metadata:

<summary>
{{ summary }}
</summary>

<metadata>
{{ metadata }}
</metadata>

2. Next, you will be given the existing folder structure:

<folder_structure>
{{ formatted_structure }}
</folder_structure>

3. Analyze the webpage summary and metadata, and compare them to the themes or topics represented by the existing folders. Consider the following:
- Does the content of the summary or metadata clearly match any of the existing folder themes?
- Are there key words or concepts in the summary or metadata that align with folder names?
- If no existing folder seems appropriate, suggest a new folder name that would best categorize this webpage.

4. Based on your analysis, provide your suggestion in a JSON structure with the following format:
{
    "name": "Parent Folder Name",
    "id": parent_folder_id,
    "children": [
        {
            "name": "Suggested Folder Name",
            "id": suggested_folder_id  // Optional, include only if suggesting an existing folder
        }
    ]
}

Examples:
1. Suggesting an existing folder:
{
    "name": "Development",
    "id": 2,
    "children": [
        {
            "name": "Python",
            "id": 5
        }
    ]
}

2. Suggesting a new folder:
{
    "name": "Technology",
    "id": 3,
    "children": [
        {
            "name": "Artificial Intelligence"
        }
    ]
}

5. IMPORTANT: Your response must contain ONLY the valid JSON structure. Do not include any explanations, justifications, or additional text.

---

File: server\templates\suggest_tags.j2

You are tasked with suggesting 3-5 relevant tags for the following webpage summary and metadata:

<summary>
{{ summary }}
</summary>

<metadata>
{{ metadata }}
</metadata>

Your goal is to generate tags that accurately represent the main topics, themes, or key elements discussed in the summary and metadata. Follow these guidelines when selecting tags:

1. Choose tags that are concise, typically consisting of one or two words.
2. Focus on the most prominent and important concepts in the summary and metadata.
3. Avoid overly generic tags that could apply to almost any text.
4. Ensure the tags are diverse and cover different aspects of the webpage.
5. If applicable, include tags related to the subject matter, industry, or field of study.

Provide your answer as a comma-separated list of tags, without any additional text or explanation. The list should contain a minimum of 3 tags and a maximum of 5 tags.

Example output format:
tag1, tag2, tag3, tag4, tag5

Remember to adjust the number of tags based on the content of the summary and metadata, ensuring you provide at least 3 and no more than 5 tags. 
IMPORTANT! Do not provide anything else that the list of tags. Do not elaborate or explain!

---

File: server\templates\summarize_content.j2

You will be given information about a webpage. Your task is to create a brief summary describing the webpage and what it is about. Here is the information:

<webpage_info>
Metadata:
{{ metadata }}

Content:
{{ content }}
</webpage_info>

Please create a summary of 2-3 sentences that describes the webpage and its main topic or purpose. Your summary should:

1. Identify the type of webpage (e.g., article, product page, blog post, etc.)
2. Explain the main subject or theme of the content
3. Highlight any key features or important information presented on the page
4. If the webpage is news or current events related, summarize the general kinds of topics covered, not any specific story
5. Describe the web page decisively and assertively. Do not use tentative language such as "This appears to be" or "It seems that." Instead, provide a confident and direct description of the page's purpose, content, and structure.

Focus on providing a concise yet informative overview that would give someone a clear idea of what they would find if they visited this webpage. Use the metadata when available, and fall back to the content when necessary. DO NOT write anything but the summary.

IMPORTANT! Use assertive language when describing the webpage. Do NOT use language like 'appears to be' or 'is likely'.

---

File: server\requirements.txt

aiohappyeyeballs==2.4.0
aiohttp==3.10.5
aiosignal==1.3.1
annotated-types==0.7.0
anthropic==0.34.1
anyio==4.4.0
asgiref==3.8.1
asttokens==2.4.1
attrs==24.2.0
backcall==0.2.0
backoff==2.2.1
bcrypt==4.2.0
beautifulsoup4==4.12.3
bleach==6.1.0
build==1.2.1
cachetools==5.5.0
certifi==2024.7.4
charset-normalizer==3.3.2
chroma-hnswlib==0.7.6
chromadb==0.5.5
click==8.1.7
colorama==0.4.6
coloredlogs==15.0.1
decorator==5.1.1
defusedxml==0.7.1
Deprecated==1.2.14
distro==1.9.0
docopt==0.6.2
ecdsa==0.19.0
executing==2.1.0
fastapi==0.112.2
fastjsonschema==2.20.0
filelock==3.15.4
flatbuffers==24.3.25
frozenlist==1.4.1
fsspec==2024.6.1
google-auth==2.34.0
googleapis-common-protos==1.63.2
greenlet==3.0.3
grpcio==1.66.0
h11==0.14.0
httpcore==1.0.5
httptools==0.6.1
httpx==0.27.0
huggingface-hub==0.24.6
humanfriendly==10.0
idna==3.8
importlib_metadata==8.0.0
importlib_resources==6.4.4
iniconfig==2.0.0
ipython==8.12.3
jedi==0.19.1
Jinja2==3.1.4
jiter==0.5.0
jsonschema==4.23.0
jsonschema-specifications==2023.12.1
jupyter_client==8.6.2
jupyter_core==5.7.2
jupyterlab_pygments==0.3.0
kubernetes==30.1.0
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib-inline==0.1.7
mdurl==0.1.2
mistune==3.0.2
mmh3==4.1.0
monotonic==1.6
mpmath==1.3.0
multidict==6.0.5
nbclient==0.10.0
nbconvert==7.16.4
nbformat==5.10.4
numpy==1.26.4
oauthlib==3.2.2
ollama==0.3.1
onnxruntime==1.19.0
openai==1.42.0
opentelemetry-api==1.26.0
opentelemetry-exporter-otlp-proto-common==1.26.0
opentelemetry-exporter-otlp-proto-grpc==1.26.0
opentelemetry-instrumentation==0.47b0
opentelemetry-instrumentation-asgi==0.47b0
opentelemetry-instrumentation-fastapi==0.47b0
opentelemetry-proto==1.26.0
opentelemetry-sdk==1.26.0
opentelemetry-semantic-conventions==0.47b0
opentelemetry-util-http==0.47b0
orjson==3.10.7
overrides==7.7.0
packaging==24.1
pandocfilters==1.5.1
parso==0.8.4
passlib==1.7.4
pickleshare==0.7.5
pipreqs==0.5.0
platformdirs==4.2.2
pluggy==1.5.0
posthog==3.5.2
prompt_toolkit==3.0.47
protobuf==4.25.4
pure_eval==0.2.3
pyasn1==0.6.0
pyasn1_modules==0.4.0
pydantic==2.8.2
pydantic_core==2.20.1
Pygments==2.18.0
PyPika==0.48.9
pyproject_hooks==1.1.0
pyreadline3==3.4.1
pytest==8.3.2
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
python-jose==3.3.0
python-multipart==0.0.9
PyYAML==6.0.2
pyzmq==26.2.0
referencing==0.35.1
requests==2.32.3
requests-oauthlib==2.0.0
rich==13.7.1
rpds-py==0.20.0
rsa==4.9
setuptools==73.0.1
shellingham==1.5.4
six==1.16.0
sniffio==1.3.1
soupsieve==2.6
SQLAlchemy==2.0.32
stack-data==0.6.3
starlette==0.38.2
sympy==1.13.2
tenacity==9.0.0
tinycss2==1.3.0
tokenizers==0.20.0
tornado==6.4.1
tqdm==4.66.5
traitlets==5.14.3
typer==0.12.5
typing_extensions==4.12.2
urllib3==2.2.2
uvicorn==0.30.6
watchfiles==0.23.0
wcwidth==0.2.13
webencodings==0.5.1
websocket-client==1.8.0
websockets==13.0
wrapt==1.16.0
yarg==0.1.9
yarl==1.9.4
zipp==3.20.0


---

File: server\content_extractor.py

from urllib.parse import urlparse
from bs4 import BeautifulSoup

class ContentExtractor:
    def __init__(self, fetch_function):
        self.fetch = fetch_function

    async def extract_content(self, url):
        parsed_url = urlparse(url)
        
        # Special handling for YouTube channels
        if self.is_youtube_channel(parsed_url):
            return self.extract_youtube_channel_info(parsed_url)
        
        # For all other URLs, including YouTube videos and playlists
        response = await self.fetch(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        meta_info = self.extract_meta_information(soup)
        
        if 'youtube.com' in parsed_url.netloc or 'youtu.be' in parsed_url.netloc:
            url_type = self.classify_youtube_url(parsed_url)
            return self.format_youtube_content(url_type, meta_info)
        else:
            return self.format_generic_content(meta_info)

    def is_youtube_channel(self, parsed_url):
        return ('youtube.com' in parsed_url.netloc and 
                (parsed_url.path.startswith('/@') or '/channel/' in parsed_url.path or '/c/' in parsed_url.path))

    def extract_youtube_channel_info(self, parsed_url):
        channel_name = parsed_url.path.split('/')[-1]
        if channel_name.startswith('@'):
            channel_name = channel_name[1:]  # Remove the '@' symbol
        
        meta_text = f"Type: YouTube Channel\n"
        meta_text += f"Channel Name: {channel_name}\n"
        meta_text += f"URL: {parsed_url.geturl()}\n"
        
        content = f"YouTube channel for {channel_name}"
        
        return meta_text, content

    def classify_youtube_url(self, parsed_url):
        if 'watch' in parsed_url.path:
            return 'video'
        elif 'playlist' in parsed_url.path:
            return 'playlist'
        else:
            return 'unknown'

    def extract_meta_information(self, soup):
        meta_info = {}

        # Extracting title
        if soup.title:
            meta_info['title'] = soup.title.string

        # Extracting meta tags
        for meta in soup.find_all('meta'):
            if 'name' in meta.attrs:
                name = meta.attrs['name'].lower()
                if name in ['description', 'keywords']:
                    meta_info[name] = meta.attrs['content']
            elif 'property' in meta.attrs:
                property_name = meta.attrs['property'].lower()
                if property_name in ['og:title', 'og:description', 'og:image', 'og:url', 'og:type']:
                    meta_info[property_name] = meta.attrs['content']

        # Extracting tags (keywords)
        if 'keywords' in meta_info:
            meta_info['tags'] = [tag.strip() for tag in meta_info['keywords'].split(',')]

        return meta_info

    def format_youtube_content(self, url_type, meta_info):
        meta_text = f"Type: YouTube {url_type.capitalize()}\n"
        meta_text += f"Title: {meta_info.get('og:title', meta_info.get('title', 'Unknown'))}\n"
        meta_text += f"Description: {meta_info.get('og:description', meta_info.get('description', 'No description found'))}\n"
        meta_text += f"URL: {meta_info.get('og:url', 'Unknown URL')}\n"
        
        if 'og:image' in meta_info:
            meta_text += f"Thumbnail: {meta_info['og:image']}\n"
        
        if 'tags' in meta_info:
            meta_text += f"Tags: {', '.join(meta_info['tags'])}\n"

        content = meta_info.get('og:description', meta_info.get('description', 'No content found'))

        return meta_text, content

    def format_generic_content(self, meta_info):
        meta_text = f"Title: {meta_info.get('og:title', meta_info.get('title', 'Unknown'))}\n"
        meta_text += f"Description: {meta_info.get('og:description', meta_info.get('description', 'No description found'))}\n"
        
        if 'og:url' in meta_info:
            meta_text += f"URL: {meta_info['og:url']}\n"
        
        if 'og:image' in meta_info:
            meta_text += f"Image: {meta_info['og:image']}\n"
        
        if 'og:type' in meta_info:
            meta_text += f"Type: {meta_info['og:type']}\n"
        
        if 'tags' in meta_info:
            meta_text += f"Tags: {', '.join(meta_info['tags'])}\n"

        content = meta_info.get('og:description', meta_info.get('description', 'No content found'))

        return meta_text, content

---

File: server\cleanTasksDB.py

import logging
from sqlalchemy import create_engine, desc
from sqlalchemy.orm import sessionmaker
from models import Task, Base, FavoriteToProcess

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Initialize SQLAlchemy
engine = create_engine('sqlite:///favorites.db', echo=True)
Session = sessionmaker(bind=engine)
session = Session()

def clean_task_table():
    try:
        # Remove all failed tasks
        failed_tasks = session.query(Task).filter(Task.status == "failed").all()
        for task in failed_tasks:
            session.delete(task)
        logger.info(f"Removed {len(failed_tasks)} failed tasks.")

        # Keep only the most recent "Restart" task
        restart_tasks = session.query(Task).filter(Task.name.like("%Restart%")).order_by(desc(Task.created_at)).all()
        if restart_tasks:
            latest_restart = restart_tasks[0]
            for task in restart_tasks[1:]:
                session.delete(task)
            logger.info(f"Kept the most recent Restart task (ID: {latest_restart.id}) and removed {len(restart_tasks) - 1} older Restart tasks.")
        else:
            logger.info("No Restart tasks found.")

        # Remove all records from favorites_to_process table
        favorites_to_process_count = session.query(FavoriteToProcess).delete()
        logger.info(f"Removed {favorites_to_process_count} records from favorites_to_process table.")

        # Commit the changes
        session.commit()
        logger.info("Task table cleaned successfully.")

    except Exception as e:
        logger.error(f"An error occurred while cleaning the task table: {str(e)}")
        session.rollback()
    finally:
        session.close()

if __name__ == "__main__":
    logger.info("Starting task table cleanup...")
    clean_task_table()
    logger.info("Task table cleanup completed.")

---

File: Dockerfile

# Use Python 3.12 slim image
FROM python:3.12-slim

# Set the working directory in the container
WORKDIR /app

# Copy the current directory contents into the container at /app
COPY ./server /app

# Upgrade pip and install dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Make port 8000 available to the world outside this container
EXPOSE 8000

# Set default values for data directories, but allow them to be overridden
ENV SQLITE_DIR=/data/sqlite
ENV CHROMA_DIR=/data/chroma

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]

---

File: server\update_data_paths.py

import os

# Get the database directories from environment variables
sqlite_dir = os.environ.get('SQLITE_DIR', '/data/sqlite')
chroma_dir = os.environ.get('CHROMA_DIR', '/data/chroma')

# Ensure the directories exist
os.makedirs(sqlite_dir, exist_ok=True)
os.makedirs(chroma_dir, exist_ok=True)

# Set the database file paths
sqlite_file = os.path.join(sqlite_dir, 'favorites.db')

# Update the SQLite database URL in the configuration
config_file = 'database.py'
with open(config_file, 'r') as file:
    content = file.read()

# Replace the SQLALCHEMY_DATABASE_URL
new_content = content.replace(
    "SQLALCHEMY_DATABASE_URL = \"sqlite:///./favorites.db\"",
    f"SQLALCHEMY_DATABASE_URL = \"sqlite:///{sqlite_file}\""
)

# Write the updated content back to the file
with open(config_file, 'w') as file:
    file.write(new_content)

print(f"SQLite database path updated to: {sqlite_file}")

# Update the Chroma database path
vector_store_file = 'vector_store.py'
with open(vector_store_file, 'r') as file:
    content = file.read()

# Replace the Chroma persistence directory
new_content = content.replace(
    "persist_directory='chroma_db'",
    f"persist_directory='{chroma_dir}'"
)

# Write the updated content back to the file
with open(vector_store_file, 'w') as file:
    file.write(new_content)

print(f"Chroma database path updated to: {chroma_dir}")

---

